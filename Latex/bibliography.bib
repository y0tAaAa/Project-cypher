@article{sokolova2024comparison,
  title={Comparison of Machine Learning Approaches for Sentiment Analysis in Slovak},
  author={Sokolov{\'a}, Zuzana and Harahus, Maro{\v{s}} and Juh{\'a}r, Jozef and Pleva, Mat{\'u}{\v{s}} and Sta{\v{s}}, J{\'a}n and Hl{\'a}dek, Daniel},
  journal={Electronics},
  volume={13},
  number={4},
  pages={703},
  year={2024},
  publisher={MDPI}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@book{singh2000code,
  title={The code book: the science of secrecy from ancient Egypt to quantum cryptography},
  author={Singh, Simon},
  year={2000},
  publisher={Anchor}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={4171--4186},
  year={2019}
}

@book{katz2020introduction,
  title={Introduction to modern cryptography},
  author={Katz, Jonathan and Lindell, Yehuda},
  year={2020},
  publisher={CRC press}
}

@article{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and others},
  journal={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={38--45},
  year={2020}
}