{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.999900225490392,
  "eval_steps": 500,
  "global_step": 75168,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003990980384331411,
      "grad_norm": 10.260724067687988,
      "learning_rate": 4.993813856960409e-05,
      "loss": 2.6409,
      "step": 100
    },
    {
      "epoch": 0.007981960768662822,
      "grad_norm": 9.569883346557617,
      "learning_rate": 4.9871620902511715e-05,
      "loss": 2.2975,
      "step": 200
    },
    {
      "epoch": 0.011972941152994233,
      "grad_norm": 9.826536178588867,
      "learning_rate": 4.980510323541933e-05,
      "loss": 2.2595,
      "step": 300
    },
    {
      "epoch": 0.015963921537325645,
      "grad_norm": 5.133543491363525,
      "learning_rate": 4.973858556832695e-05,
      "loss": 2.1432,
      "step": 400
    },
    {
      "epoch": 0.019954901921657053,
      "grad_norm": 7.61666202545166,
      "learning_rate": 4.967206790123457e-05,
      "loss": 2.0539,
      "step": 500
    },
    {
      "epoch": 0.019954901921657053,
      "eval_loss": 2.036983013153076,
      "eval_runtime": 571.2384,
      "eval_samples_per_second": 10.966,
      "eval_steps_per_second": 10.966,
      "step": 500
    },
    {
      "epoch": 0.023945882305988465,
      "grad_norm": 8.41107177734375,
      "learning_rate": 4.960555023414219e-05,
      "loss": 2.1403,
      "step": 600
    },
    {
      "epoch": 0.027936862690319877,
      "grad_norm": 10.01880931854248,
      "learning_rate": 4.953903256704981e-05,
      "loss": 2.1215,
      "step": 700
    },
    {
      "epoch": 0.03192784307465129,
      "grad_norm": 7.7169508934021,
      "learning_rate": 4.9472514899957425e-05,
      "loss": 2.0108,
      "step": 800
    },
    {
      "epoch": 0.0359188234589827,
      "grad_norm": 7.566656112670898,
      "learning_rate": 4.940599723286505e-05,
      "loss": 1.995,
      "step": 900
    },
    {
      "epoch": 0.03990980384331411,
      "grad_norm": 5.232861042022705,
      "learning_rate": 4.9339479565772676e-05,
      "loss": 1.9323,
      "step": 1000
    },
    {
      "epoch": 0.03990980384331411,
      "eval_loss": 1.922892689704895,
      "eval_runtime": 573.7835,
      "eval_samples_per_second": 10.917,
      "eval_steps_per_second": 10.917,
      "step": 1000
    },
    {
      "epoch": 0.04390078422764552,
      "grad_norm": 7.435717582702637,
      "learning_rate": 4.9272961898680294e-05,
      "loss": 1.9227,
      "step": 1100
    },
    {
      "epoch": 0.04789176461197693,
      "grad_norm": 7.299289703369141,
      "learning_rate": 4.920644423158791e-05,
      "loss": 1.8557,
      "step": 1200
    },
    {
      "epoch": 0.05188274499630834,
      "grad_norm": 5.2556939125061035,
      "learning_rate": 4.913992656449553e-05,
      "loss": 1.9514,
      "step": 1300
    },
    {
      "epoch": 0.055873725380639755,
      "grad_norm": 6.345143795013428,
      "learning_rate": 4.907340889740315e-05,
      "loss": 2.0001,
      "step": 1400
    },
    {
      "epoch": 0.05986470576497117,
      "grad_norm": 6.914944171905518,
      "learning_rate": 4.9006891230310774e-05,
      "loss": 2.0389,
      "step": 1500
    },
    {
      "epoch": 0.05986470576497117,
      "eval_loss": 1.855600118637085,
      "eval_runtime": 578.0001,
      "eval_samples_per_second": 10.837,
      "eval_steps_per_second": 10.837,
      "step": 1500
    },
    {
      "epoch": 0.06385568614930258,
      "grad_norm": 5.232017517089844,
      "learning_rate": 4.894037356321839e-05,
      "loss": 1.8543,
      "step": 1600
    },
    {
      "epoch": 0.06784666653363398,
      "grad_norm": 5.42081880569458,
      "learning_rate": 4.887385589612601e-05,
      "loss": 1.9847,
      "step": 1700
    },
    {
      "epoch": 0.0718376469179654,
      "grad_norm": 4.535865783691406,
      "learning_rate": 4.8807338229033636e-05,
      "loss": 1.8743,
      "step": 1800
    },
    {
      "epoch": 0.07582862730229681,
      "grad_norm": 6.151806354522705,
      "learning_rate": 4.8740820561941255e-05,
      "loss": 1.8286,
      "step": 1900
    },
    {
      "epoch": 0.07981960768662821,
      "grad_norm": 6.822512149810791,
      "learning_rate": 4.867430289484887e-05,
      "loss": 1.8901,
      "step": 2000
    },
    {
      "epoch": 0.07981960768662821,
      "eval_loss": 1.8134870529174805,
      "eval_runtime": 576.8433,
      "eval_samples_per_second": 10.859,
      "eval_steps_per_second": 10.859,
      "step": 2000
    },
    {
      "epoch": 0.08381058807095963,
      "grad_norm": 3.9056966304779053,
      "learning_rate": 4.86077852277565e-05,
      "loss": 1.8942,
      "step": 2100
    },
    {
      "epoch": 0.08780156845529104,
      "grad_norm": 4.648974895477295,
      "learning_rate": 4.854126756066412e-05,
      "loss": 1.8694,
      "step": 2200
    },
    {
      "epoch": 0.09179254883962246,
      "grad_norm": 6.74287223815918,
      "learning_rate": 4.8474749893571735e-05,
      "loss": 1.8912,
      "step": 2300
    },
    {
      "epoch": 0.09578352922395386,
      "grad_norm": 4.142402172088623,
      "learning_rate": 4.8408232226479354e-05,
      "loss": 1.8587,
      "step": 2400
    },
    {
      "epoch": 0.09977450960828528,
      "grad_norm": 4.386350631713867,
      "learning_rate": 4.834171455938697e-05,
      "loss": 1.8286,
      "step": 2500
    },
    {
      "epoch": 0.09977450960828528,
      "eval_loss": 1.7808421850204468,
      "eval_runtime": 574.1661,
      "eval_samples_per_second": 10.91,
      "eval_steps_per_second": 10.91,
      "step": 2500
    },
    {
      "epoch": 0.10376548999261669,
      "grad_norm": 5.60428524017334,
      "learning_rate": 4.82751968922946e-05,
      "loss": 1.9151,
      "step": 2600
    },
    {
      "epoch": 0.10775647037694809,
      "grad_norm": 3.6972274780273438,
      "learning_rate": 4.8208679225202216e-05,
      "loss": 1.7793,
      "step": 2700
    },
    {
      "epoch": 0.11174745076127951,
      "grad_norm": 5.322393417358398,
      "learning_rate": 4.814216155810984e-05,
      "loss": 1.8384,
      "step": 2800
    },
    {
      "epoch": 0.11573843114561091,
      "grad_norm": 5.790696620941162,
      "learning_rate": 4.807564389101746e-05,
      "loss": 1.8563,
      "step": 2900
    },
    {
      "epoch": 0.11972941152994233,
      "grad_norm": 4.710314750671387,
      "learning_rate": 4.800912622392508e-05,
      "loss": 1.8234,
      "step": 3000
    },
    {
      "epoch": 0.11972941152994233,
      "eval_loss": 1.7446835041046143,
      "eval_runtime": 581.3221,
      "eval_samples_per_second": 10.775,
      "eval_steps_per_second": 10.775,
      "step": 3000
    },
    {
      "epoch": 0.12372039191427374,
      "grad_norm": 5.354876518249512,
      "learning_rate": 4.7942608556832696e-05,
      "loss": 1.8302,
      "step": 3100
    },
    {
      "epoch": 0.12771137229860516,
      "grad_norm": 4.510046482086182,
      "learning_rate": 4.7876090889740314e-05,
      "loss": 1.7921,
      "step": 3200
    },
    {
      "epoch": 0.13170235268293656,
      "grad_norm": 4.528976917266846,
      "learning_rate": 4.780957322264793e-05,
      "loss": 1.7974,
      "step": 3300
    },
    {
      "epoch": 0.13569333306726797,
      "grad_norm": 6.270905017852783,
      "learning_rate": 4.774305555555556e-05,
      "loss": 1.9261,
      "step": 3400
    },
    {
      "epoch": 0.13968431345159937,
      "grad_norm": 2.8325035572052,
      "learning_rate": 4.7676537888463176e-05,
      "loss": 1.774,
      "step": 3500
    },
    {
      "epoch": 0.13968431345159937,
      "eval_loss": 1.7246748208999634,
      "eval_runtime": 1149.2191,
      "eval_samples_per_second": 5.451,
      "eval_steps_per_second": 5.451,
      "step": 3500
    },
    {
      "epoch": 0.1436752938359308,
      "grad_norm": 3.802029848098755,
      "learning_rate": 4.76100202213708e-05,
      "loss": 1.6631,
      "step": 3600
    },
    {
      "epoch": 0.1476662742202622,
      "grad_norm": 3.673377275466919,
      "learning_rate": 4.754350255427842e-05,
      "loss": 1.7168,
      "step": 3700
    },
    {
      "epoch": 0.15165725460459362,
      "grad_norm": 3.4533541202545166,
      "learning_rate": 4.747698488718604e-05,
      "loss": 1.7069,
      "step": 3800
    },
    {
      "epoch": 0.15564823498892502,
      "grad_norm": 4.362922191619873,
      "learning_rate": 4.741046722009366e-05,
      "loss": 1.897,
      "step": 3900
    },
    {
      "epoch": 0.15963921537325643,
      "grad_norm": 5.0844645500183105,
      "learning_rate": 4.7343949553001275e-05,
      "loss": 1.8005,
      "step": 4000
    },
    {
      "epoch": 0.15963921537325643,
      "eval_loss": 1.6720937490463257,
      "eval_runtime": 580.4726,
      "eval_samples_per_second": 10.791,
      "eval_steps_per_second": 10.791,
      "step": 4000
    },
    {
      "epoch": 0.16363019575758786,
      "grad_norm": 5.310273170471191,
      "learning_rate": 4.72774318859089e-05,
      "loss": 1.7097,
      "step": 4100
    },
    {
      "epoch": 0.16762117614191926,
      "grad_norm": 4.479982852935791,
      "learning_rate": 4.721091421881652e-05,
      "loss": 1.7812,
      "step": 4200
    },
    {
      "epoch": 0.17161215652625067,
      "grad_norm": 5.075533390045166,
      "learning_rate": 4.714439655172414e-05,
      "loss": 1.6749,
      "step": 4300
    },
    {
      "epoch": 0.17560313691058207,
      "grad_norm": 4.475705146789551,
      "learning_rate": 4.707787888463176e-05,
      "loss": 1.6934,
      "step": 4400
    },
    {
      "epoch": 0.1795941172949135,
      "grad_norm": 4.344222068786621,
      "learning_rate": 4.701136121753938e-05,
      "loss": 1.5997,
      "step": 4500
    },
    {
      "epoch": 0.1795941172949135,
      "eval_loss": 1.5052863359451294,
      "eval_runtime": 580.2238,
      "eval_samples_per_second": 10.796,
      "eval_steps_per_second": 10.796,
      "step": 4500
    },
    {
      "epoch": 0.1835850976792449,
      "grad_norm": 4.912107467651367,
      "learning_rate": 4.6944843550447e-05,
      "loss": 1.548,
      "step": 4600
    },
    {
      "epoch": 0.18757607806357632,
      "grad_norm": 4.992293834686279,
      "learning_rate": 4.6878325883354624e-05,
      "loss": 1.5532,
      "step": 4700
    },
    {
      "epoch": 0.19156705844790772,
      "grad_norm": 4.174944877624512,
      "learning_rate": 4.681180821626224e-05,
      "loss": 1.5357,
      "step": 4800
    },
    {
      "epoch": 0.19555803883223913,
      "grad_norm": 5.109267711639404,
      "learning_rate": 4.674529054916986e-05,
      "loss": 1.6081,
      "step": 4900
    },
    {
      "epoch": 0.19954901921657056,
      "grad_norm": 1.3576960563659668,
      "learning_rate": 4.667877288207748e-05,
      "loss": 1.5256,
      "step": 5000
    },
    {
      "epoch": 0.19954901921657056,
      "eval_loss": 1.3687196969985962,
      "eval_runtime": 577.9534,
      "eval_samples_per_second": 10.838,
      "eval_steps_per_second": 10.838,
      "step": 5000
    },
    {
      "epoch": 0.20353999960090197,
      "grad_norm": 4.736396789550781,
      "learning_rate": 4.66122552149851e-05,
      "loss": 1.4976,
      "step": 5100
    },
    {
      "epoch": 0.20753097998523337,
      "grad_norm": 4.528829574584961,
      "learning_rate": 4.654573754789272e-05,
      "loss": 1.4541,
      "step": 5200
    },
    {
      "epoch": 0.21152196036956478,
      "grad_norm": 3.485330820083618,
      "learning_rate": 4.647921988080035e-05,
      "loss": 1.4581,
      "step": 5300
    },
    {
      "epoch": 0.21551294075389618,
      "grad_norm": 3.430171012878418,
      "learning_rate": 4.641270221370797e-05,
      "loss": 1.458,
      "step": 5400
    },
    {
      "epoch": 0.21950392113822761,
      "grad_norm": 3.6046524047851562,
      "learning_rate": 4.6346184546615585e-05,
      "loss": 1.3969,
      "step": 5500
    },
    {
      "epoch": 0.21950392113822761,
      "eval_loss": 1.2711880207061768,
      "eval_runtime": 578.8541,
      "eval_samples_per_second": 10.821,
      "eval_steps_per_second": 10.821,
      "step": 5500
    },
    {
      "epoch": 0.22349490152255902,
      "grad_norm": 6.041763782501221,
      "learning_rate": 4.6279666879523204e-05,
      "loss": 1.4074,
      "step": 5600
    },
    {
      "epoch": 0.22748588190689042,
      "grad_norm": 4.668428421020508,
      "learning_rate": 4.621314921243082e-05,
      "loss": 1.4322,
      "step": 5700
    },
    {
      "epoch": 0.23147686229122183,
      "grad_norm": 5.3936076164245605,
      "learning_rate": 4.614663154533844e-05,
      "loss": 1.328,
      "step": 5800
    },
    {
      "epoch": 0.23546784267555326,
      "grad_norm": 5.261631011962891,
      "learning_rate": 4.608011387824606e-05,
      "loss": 1.3953,
      "step": 5900
    },
    {
      "epoch": 0.23945882305988467,
      "grad_norm": 4.709071636199951,
      "learning_rate": 4.6013596211153684e-05,
      "loss": 1.3515,
      "step": 6000
    },
    {
      "epoch": 0.23945882305988467,
      "eval_loss": 1.207901120185852,
      "eval_runtime": 577.2213,
      "eval_samples_per_second": 10.852,
      "eval_steps_per_second": 10.852,
      "step": 6000
    },
    {
      "epoch": 0.24344980344421607,
      "grad_norm": 3.6400609016418457,
      "learning_rate": 4.594707854406131e-05,
      "loss": 1.2399,
      "step": 6100
    },
    {
      "epoch": 0.24744078382854748,
      "grad_norm": 5.832128524780273,
      "learning_rate": 4.588056087696893e-05,
      "loss": 1.3455,
      "step": 6200
    },
    {
      "epoch": 0.2514317642128789,
      "grad_norm": 3.7093756198883057,
      "learning_rate": 4.5814043209876546e-05,
      "loss": 1.3542,
      "step": 6300
    },
    {
      "epoch": 0.2554227445972103,
      "grad_norm": 3.6710994243621826,
      "learning_rate": 4.5747525542784164e-05,
      "loss": 1.3058,
      "step": 6400
    },
    {
      "epoch": 0.2594137249815417,
      "grad_norm": 4.063559532165527,
      "learning_rate": 4.568100787569178e-05,
      "loss": 1.2788,
      "step": 6500
    },
    {
      "epoch": 0.2594137249815417,
      "eval_loss": 1.1567208766937256,
      "eval_runtime": 586.9732,
      "eval_samples_per_second": 10.672,
      "eval_steps_per_second": 10.672,
      "step": 6500
    },
    {
      "epoch": 0.2634047053658731,
      "grad_norm": 3.335392475128174,
      "learning_rate": 4.561449020859941e-05,
      "loss": 1.2127,
      "step": 6600
    },
    {
      "epoch": 0.26739568575020456,
      "grad_norm": 3.4721450805664062,
      "learning_rate": 4.5547972541507026e-05,
      "loss": 1.1898,
      "step": 6700
    },
    {
      "epoch": 0.27138666613453594,
      "grad_norm": 3.763205051422119,
      "learning_rate": 4.5481454874414645e-05,
      "loss": 1.1986,
      "step": 6800
    },
    {
      "epoch": 0.27537764651886737,
      "grad_norm": 4.298484802246094,
      "learning_rate": 4.541493720732227e-05,
      "loss": 1.2469,
      "step": 6900
    },
    {
      "epoch": 0.27936862690319875,
      "grad_norm": 4.309507846832275,
      "learning_rate": 4.534841954022989e-05,
      "loss": 1.196,
      "step": 7000
    },
    {
      "epoch": 0.27936862690319875,
      "eval_loss": 1.1227803230285645,
      "eval_runtime": 588.4744,
      "eval_samples_per_second": 10.644,
      "eval_steps_per_second": 10.644,
      "step": 7000
    },
    {
      "epoch": 0.2833596072875302,
      "grad_norm": 3.0981104373931885,
      "learning_rate": 4.528190187313751e-05,
      "loss": 1.1797,
      "step": 7100
    },
    {
      "epoch": 0.2873505876718616,
      "grad_norm": 4.513011932373047,
      "learning_rate": 4.521538420604513e-05,
      "loss": 1.1653,
      "step": 7200
    },
    {
      "epoch": 0.291341568056193,
      "grad_norm": 3.8284494876861572,
      "learning_rate": 4.514886653895275e-05,
      "loss": 1.2416,
      "step": 7300
    },
    {
      "epoch": 0.2953325484405244,
      "grad_norm": 3.4725184440612793,
      "learning_rate": 4.508234887186037e-05,
      "loss": 1.147,
      "step": 7400
    },
    {
      "epoch": 0.2993235288248558,
      "grad_norm": 5.012810707092285,
      "learning_rate": 4.501583120476799e-05,
      "loss": 1.2436,
      "step": 7500
    },
    {
      "epoch": 0.2993235288248558,
      "eval_loss": 1.0871107578277588,
      "eval_runtime": 593.8319,
      "eval_samples_per_second": 10.548,
      "eval_steps_per_second": 10.548,
      "step": 7500
    },
    {
      "epoch": 0.30331450920918723,
      "grad_norm": 4.383472919464111,
      "learning_rate": 4.4949313537675606e-05,
      "loss": 1.2329,
      "step": 7600
    },
    {
      "epoch": 0.30730548959351867,
      "grad_norm": 4.612908363342285,
      "learning_rate": 4.4882795870583224e-05,
      "loss": 1.1625,
      "step": 7700
    },
    {
      "epoch": 0.31129646997785004,
      "grad_norm": 4.691483497619629,
      "learning_rate": 4.481627820349085e-05,
      "loss": 1.168,
      "step": 7800
    },
    {
      "epoch": 0.3152874503621815,
      "grad_norm": 3.7274932861328125,
      "learning_rate": 4.4749760536398474e-05,
      "loss": 1.1922,
      "step": 7900
    },
    {
      "epoch": 0.31927843074651285,
      "grad_norm": 4.231459617614746,
      "learning_rate": 4.468324286930609e-05,
      "loss": 1.1822,
      "step": 8000
    },
    {
      "epoch": 0.31927843074651285,
      "eval_loss": 1.0561878681182861,
      "eval_runtime": 656.5248,
      "eval_samples_per_second": 9.541,
      "eval_steps_per_second": 9.541,
      "step": 8000
    },
    {
      "epoch": 0.3232694111308443,
      "grad_norm": 3.352534770965576,
      "learning_rate": 4.461672520221371e-05,
      "loss": 1.1674,
      "step": 8100
    },
    {
      "epoch": 0.3272603915151757,
      "grad_norm": 4.060751914978027,
      "learning_rate": 4.455020753512133e-05,
      "loss": 1.1789,
      "step": 8200
    },
    {
      "epoch": 0.3312513718995071,
      "grad_norm": 2.7887301445007324,
      "learning_rate": 4.448368986802895e-05,
      "loss": 1.1291,
      "step": 8300
    },
    {
      "epoch": 0.33524235228383853,
      "grad_norm": 2.6528749465942383,
      "learning_rate": 4.4417172200936567e-05,
      "loss": 1.1617,
      "step": 8400
    },
    {
      "epoch": 0.33923333266816996,
      "grad_norm": 3.628490924835205,
      "learning_rate": 4.435065453384419e-05,
      "loss": 1.0935,
      "step": 8500
    },
    {
      "epoch": 0.33923333266816996,
      "eval_loss": 1.0424227714538574,
      "eval_runtime": 597.3228,
      "eval_samples_per_second": 10.487,
      "eval_steps_per_second": 10.487,
      "step": 8500
    },
    {
      "epoch": 0.34322431305250134,
      "grad_norm": 3.8421554565429688,
      "learning_rate": 4.428413686675181e-05,
      "loss": 1.0935,
      "step": 8600
    },
    {
      "epoch": 0.3472152934368328,
      "grad_norm": 4.553176403045654,
      "learning_rate": 4.4217619199659435e-05,
      "loss": 1.1013,
      "step": 8700
    },
    {
      "epoch": 0.35120627382116415,
      "grad_norm": 4.5950140953063965,
      "learning_rate": 4.4151101532567054e-05,
      "loss": 1.1193,
      "step": 8800
    },
    {
      "epoch": 0.3551972542054956,
      "grad_norm": 4.905737400054932,
      "learning_rate": 4.408458386547467e-05,
      "loss": 1.0674,
      "step": 8900
    },
    {
      "epoch": 0.359188234589827,
      "grad_norm": 5.886459827423096,
      "learning_rate": 4.401806619838229e-05,
      "loss": 1.0984,
      "step": 9000
    },
    {
      "epoch": 0.359188234589827,
      "eval_loss": 1.0195435285568237,
      "eval_runtime": 598.6138,
      "eval_samples_per_second": 10.464,
      "eval_steps_per_second": 10.464,
      "step": 9000
    },
    {
      "epoch": 0.3631792149741584,
      "grad_norm": 3.9636447429656982,
      "learning_rate": 4.395154853128991e-05,
      "loss": 1.0909,
      "step": 9100
    },
    {
      "epoch": 0.3671701953584898,
      "grad_norm": 5.005570888519287,
      "learning_rate": 4.3885030864197534e-05,
      "loss": 0.9927,
      "step": 9200
    },
    {
      "epoch": 0.3711611757428212,
      "grad_norm": 1.4548025131225586,
      "learning_rate": 4.381851319710515e-05,
      "loss": 1.0608,
      "step": 9300
    },
    {
      "epoch": 0.37515215612715264,
      "grad_norm": 5.12683629989624,
      "learning_rate": 4.375199553001277e-05,
      "loss": 1.0922,
      "step": 9400
    },
    {
      "epoch": 0.37914313651148407,
      "grad_norm": 3.22308349609375,
      "learning_rate": 4.3685477862920396e-05,
      "loss": 1.1046,
      "step": 9500
    },
    {
      "epoch": 0.37914313651148407,
      "eval_loss": 1.0061383247375488,
      "eval_runtime": 671.8332,
      "eval_samples_per_second": 9.324,
      "eval_steps_per_second": 9.324,
      "step": 9500
    },
    {
      "epoch": 0.38313411689581545,
      "grad_norm": 3.7932486534118652,
      "learning_rate": 4.3618960195828015e-05,
      "loss": 1.0641,
      "step": 9600
    },
    {
      "epoch": 0.3871250972801469,
      "grad_norm": 4.321405410766602,
      "learning_rate": 4.355244252873563e-05,
      "loss": 1.0689,
      "step": 9700
    },
    {
      "epoch": 0.39111607766447826,
      "grad_norm": 4.865998268127441,
      "learning_rate": 4.348592486164326e-05,
      "loss": 1.0948,
      "step": 9800
    },
    {
      "epoch": 0.3951070580488097,
      "grad_norm": 3.2902491092681885,
      "learning_rate": 4.3419407194550877e-05,
      "loss": 1.0454,
      "step": 9900
    },
    {
      "epoch": 0.3990980384331411,
      "grad_norm": 3.846095561981201,
      "learning_rate": 4.3352889527458495e-05,
      "loss": 1.0799,
      "step": 10000
    },
    {
      "epoch": 0.3990980384331411,
      "eval_loss": 0.9909156560897827,
      "eval_runtime": 638.2435,
      "eval_samples_per_second": 9.814,
      "eval_steps_per_second": 9.814,
      "step": 10000
    },
    {
      "epoch": 0.4030890188174725,
      "grad_norm": 2.9474987983703613,
      "learning_rate": 4.328637186036611e-05,
      "loss": 1.0138,
      "step": 10100
    },
    {
      "epoch": 0.40707999920180393,
      "grad_norm": 1.3991650342941284,
      "learning_rate": 4.321985419327373e-05,
      "loss": 1.03,
      "step": 10200
    },
    {
      "epoch": 0.4110709795861353,
      "grad_norm": 3.719278335571289,
      "learning_rate": 4.315333652618136e-05,
      "loss": 1.0796,
      "step": 10300
    },
    {
      "epoch": 0.41506195997046674,
      "grad_norm": 3.928762912750244,
      "learning_rate": 4.308681885908898e-05,
      "loss": 1.0342,
      "step": 10400
    },
    {
      "epoch": 0.4190529403547982,
      "grad_norm": 1.3328908681869507,
      "learning_rate": 4.30203011919966e-05,
      "loss": 1.0565,
      "step": 10500
    },
    {
      "epoch": 0.4190529403547982,
      "eval_loss": 0.9792885780334473,
      "eval_runtime": 1550.5224,
      "eval_samples_per_second": 4.04,
      "eval_steps_per_second": 4.04,
      "step": 10500
    },
    {
      "epoch": 0.42304392073912955,
      "grad_norm": 3.8835301399230957,
      "learning_rate": 4.295378352490422e-05,
      "loss": 1.034,
      "step": 10600
    },
    {
      "epoch": 0.427034901123461,
      "grad_norm": 2.87522554397583,
      "learning_rate": 4.288726585781184e-05,
      "loss": 1.0345,
      "step": 10700
    },
    {
      "epoch": 0.43102588150779236,
      "grad_norm": 3.9498541355133057,
      "learning_rate": 4.2820748190719456e-05,
      "loss": 1.0566,
      "step": 10800
    },
    {
      "epoch": 0.4350168618921238,
      "grad_norm": 4.102822780609131,
      "learning_rate": 4.2754230523627074e-05,
      "loss": 1.071,
      "step": 10900
    },
    {
      "epoch": 0.43900784227645523,
      "grad_norm": 4.186605453491211,
      "learning_rate": 4.2688378033205625e-05,
      "loss": 1.0809,
      "step": 11000
    },
    {
      "epoch": 0.43900784227645523,
      "eval_loss": 0.9699931740760803,
      "eval_runtime": 1177.4597,
      "eval_samples_per_second": 5.32,
      "eval_steps_per_second": 5.32,
      "step": 11000
    },
    {
      "epoch": 0.4429988226607866,
      "grad_norm": 3.6335630416870117,
      "learning_rate": 4.2621860366113244e-05,
      "loss": 1.0702,
      "step": 11100
    },
    {
      "epoch": 0.44698980304511804,
      "grad_norm": 2.902324914932251,
      "learning_rate": 4.255534269902086e-05,
      "loss": 1.0383,
      "step": 11200
    },
    {
      "epoch": 0.4509807834294494,
      "grad_norm": 3.2960009574890137,
      "learning_rate": 4.248882503192848e-05,
      "loss": 1.0513,
      "step": 11300
    },
    {
      "epoch": 0.45497176381378085,
      "grad_norm": 4.0239152908325195,
      "learning_rate": 4.24223073648361e-05,
      "loss": 1.0882,
      "step": 11400
    },
    {
      "epoch": 0.4589627441981123,
      "grad_norm": 3.0615525245666504,
      "learning_rate": 4.2355789697743724e-05,
      "loss": 1.0242,
      "step": 11500
    },
    {
      "epoch": 0.4589627441981123,
      "eval_loss": 0.9587934017181396,
      "eval_runtime": 547.7657,
      "eval_samples_per_second": 11.436,
      "eval_steps_per_second": 11.436,
      "step": 11500
    },
    {
      "epoch": 0.46295372458244366,
      "grad_norm": 4.048797607421875,
      "learning_rate": 4.228927203065134e-05,
      "loss": 1.0623,
      "step": 11600
    },
    {
      "epoch": 0.4669447049667751,
      "grad_norm": 2.1706526279449463,
      "learning_rate": 4.222275436355896e-05,
      "loss": 1.0312,
      "step": 11700
    },
    {
      "epoch": 0.4709356853511065,
      "grad_norm": 3.764509439468384,
      "learning_rate": 4.2156236696466586e-05,
      "loss": 1.0205,
      "step": 11800
    },
    {
      "epoch": 0.4749266657354379,
      "grad_norm": 3.6031155586242676,
      "learning_rate": 4.2089719029374205e-05,
      "loss": 1.0172,
      "step": 11900
    },
    {
      "epoch": 0.47891764611976934,
      "grad_norm": 3.843451738357544,
      "learning_rate": 4.202320136228182e-05,
      "loss": 1.0375,
      "step": 12000
    },
    {
      "epoch": 0.47891764611976934,
      "eval_loss": 0.9523873329162598,
      "eval_runtime": 568.5265,
      "eval_samples_per_second": 11.018,
      "eval_steps_per_second": 11.018,
      "step": 12000
    },
    {
      "epoch": 0.4829086265041007,
      "grad_norm": 3.5361745357513428,
      "learning_rate": 4.195668369518945e-05,
      "loss": 1.0221,
      "step": 12100
    },
    {
      "epoch": 0.48689960688843215,
      "grad_norm": 2.5921385288238525,
      "learning_rate": 4.189016602809707e-05,
      "loss": 1.0213,
      "step": 12200
    },
    {
      "epoch": 0.4908905872727636,
      "grad_norm": 3.393522262573242,
      "learning_rate": 4.1823648361004685e-05,
      "loss": 1.0354,
      "step": 12300
    },
    {
      "epoch": 0.49488156765709496,
      "grad_norm": 3.7947275638580322,
      "learning_rate": 4.1757130693912303e-05,
      "loss": 1.045,
      "step": 12400
    },
    {
      "epoch": 0.4988725480414264,
      "grad_norm": 4.1218976974487305,
      "learning_rate": 4.169061302681992e-05,
      "loss": 1.0201,
      "step": 12500
    },
    {
      "epoch": 0.4988725480414264,
      "eval_loss": 0.9491935968399048,
      "eval_runtime": 584.4693,
      "eval_samples_per_second": 10.717,
      "eval_steps_per_second": 10.717,
      "step": 12500
    },
    {
      "epoch": 0.5028635284257578,
      "grad_norm": 3.0362446308135986,
      "learning_rate": 4.162409535972755e-05,
      "loss": 1.0186,
      "step": 12600
    },
    {
      "epoch": 0.5068545088100892,
      "grad_norm": 3.0243279933929443,
      "learning_rate": 4.1557577692635165e-05,
      "loss": 0.955,
      "step": 12700
    },
    {
      "epoch": 0.5108454891944206,
      "grad_norm": 2.7037343978881836,
      "learning_rate": 4.149106002554279e-05,
      "loss": 1.0413,
      "step": 12800
    },
    {
      "epoch": 0.5148364695787521,
      "grad_norm": 4.309401512145996,
      "learning_rate": 4.142454235845041e-05,
      "loss": 0.9785,
      "step": 12900
    },
    {
      "epoch": 0.5188274499630834,
      "grad_norm": 7.637515544891357,
      "learning_rate": 4.135802469135803e-05,
      "loss": 0.9842,
      "step": 13000
    },
    {
      "epoch": 0.5188274499630834,
      "eval_loss": 0.9384611248970032,
      "eval_runtime": 539.6452,
      "eval_samples_per_second": 11.608,
      "eval_steps_per_second": 11.608,
      "step": 13000
    },
    {
      "epoch": 0.5228184303474148,
      "grad_norm": 3.911527395248413,
      "learning_rate": 4.1291507024265646e-05,
      "loss": 1.054,
      "step": 13100
    },
    {
      "epoch": 0.5268094107317463,
      "grad_norm": 1.7729510068893433,
      "learning_rate": 4.1224989357173264e-05,
      "loss": 0.9891,
      "step": 13200
    },
    {
      "epoch": 0.5308003911160777,
      "grad_norm": 3.6882383823394775,
      "learning_rate": 4.115847169008088e-05,
      "loss": 0.9984,
      "step": 13300
    },
    {
      "epoch": 0.5347913715004091,
      "grad_norm": 3.9141182899475098,
      "learning_rate": 4.109195402298851e-05,
      "loss": 1.0421,
      "step": 13400
    },
    {
      "epoch": 0.5387823518847404,
      "grad_norm": 3.579922676086426,
      "learning_rate": 4.102543635589613e-05,
      "loss": 0.9967,
      "step": 13500
    },
    {
      "epoch": 0.5387823518847404,
      "eval_loss": 0.9318103194236755,
      "eval_runtime": 431.3485,
      "eval_samples_per_second": 14.522,
      "eval_steps_per_second": 14.522,
      "step": 13500
    },
    {
      "epoch": 0.5427733322690719,
      "grad_norm": 2.7513413429260254,
      "learning_rate": 4.095891868880375e-05,
      "loss": 1.0225,
      "step": 13600
    },
    {
      "epoch": 0.5467643126534033,
      "grad_norm": 4.498902320861816,
      "learning_rate": 4.089240102171137e-05,
      "loss": 1.0456,
      "step": 13700
    },
    {
      "epoch": 0.5507552930377347,
      "grad_norm": 4.615011215209961,
      "learning_rate": 4.082588335461899e-05,
      "loss": 0.9844,
      "step": 13800
    },
    {
      "epoch": 0.5547462734220662,
      "grad_norm": 3.7146973609924316,
      "learning_rate": 4.075936568752661e-05,
      "loss": 0.9845,
      "step": 13900
    },
    {
      "epoch": 0.5587372538063975,
      "grad_norm": 5.393137454986572,
      "learning_rate": 4.0692848020434225e-05,
      "loss": 0.9773,
      "step": 14000
    },
    {
      "epoch": 0.5587372538063975,
      "eval_loss": 0.9270970821380615,
      "eval_runtime": 470.8486,
      "eval_samples_per_second": 13.304,
      "eval_steps_per_second": 13.304,
      "step": 14000
    },
    {
      "epoch": 0.5627282341907289,
      "grad_norm": 2.1480064392089844,
      "learning_rate": 4.0626995530012776e-05,
      "loss": 0.9636,
      "step": 14100
    },
    {
      "epoch": 0.5667192145750604,
      "grad_norm": 3.7527835369110107,
      "learning_rate": 4.0560477862920395e-05,
      "loss": 0.9994,
      "step": 14200
    },
    {
      "epoch": 0.5707101949593918,
      "grad_norm": 2.456590414047241,
      "learning_rate": 4.049396019582801e-05,
      "loss": 0.9832,
      "step": 14300
    },
    {
      "epoch": 0.5747011753437232,
      "grad_norm": 3.5774550437927246,
      "learning_rate": 4.042744252873563e-05,
      "loss": 0.9633,
      "step": 14400
    },
    {
      "epoch": 0.5786921557280545,
      "grad_norm": 3.2523674964904785,
      "learning_rate": 4.036092486164326e-05,
      "loss": 0.9466,
      "step": 14500
    },
    {
      "epoch": 0.5786921557280545,
      "eval_loss": 0.9237834811210632,
      "eval_runtime": 525.6006,
      "eval_samples_per_second": 11.918,
      "eval_steps_per_second": 11.918,
      "step": 14500
    },
    {
      "epoch": 0.582683136112386,
      "grad_norm": 2.526930332183838,
      "learning_rate": 4.0294407194550875e-05,
      "loss": 0.9966,
      "step": 14600
    },
    {
      "epoch": 0.5866741164967174,
      "grad_norm": 4.128021240234375,
      "learning_rate": 4.0227889527458494e-05,
      "loss": 0.9689,
      "step": 14700
    },
    {
      "epoch": 0.5906650968810488,
      "grad_norm": 3.3602447509765625,
      "learning_rate": 4.016137186036611e-05,
      "loss": 1.0152,
      "step": 14800
    },
    {
      "epoch": 0.5946560772653803,
      "grad_norm": 3.52284836769104,
      "learning_rate": 4.009485419327374e-05,
      "loss": 0.9793,
      "step": 14900
    },
    {
      "epoch": 0.5986470576497116,
      "grad_norm": 2.7331414222717285,
      "learning_rate": 4.0028336526181356e-05,
      "loss": 0.9972,
      "step": 15000
    },
    {
      "epoch": 0.5986470576497116,
      "eval_loss": 0.9155036211013794,
      "eval_runtime": 517.5547,
      "eval_samples_per_second": 12.103,
      "eval_steps_per_second": 12.103,
      "step": 15000
    },
    {
      "epoch": 0.602638038034043,
      "grad_norm": 3.6636011600494385,
      "learning_rate": 3.996181885908898e-05,
      "loss": 0.932,
      "step": 15100
    },
    {
      "epoch": 0.6066290184183745,
      "grad_norm": 3.0495548248291016,
      "learning_rate": 3.98953011919966e-05,
      "loss": 0.961,
      "step": 15200
    },
    {
      "epoch": 0.6106199988027059,
      "grad_norm": 3.265803337097168,
      "learning_rate": 3.982878352490422e-05,
      "loss": 0.9858,
      "step": 15300
    },
    {
      "epoch": 0.6146109791870373,
      "grad_norm": 3.4842441082000732,
      "learning_rate": 3.9762265857811836e-05,
      "loss": 0.9818,
      "step": 15400
    },
    {
      "epoch": 0.6186019595713687,
      "grad_norm": 3.4083902835845947,
      "learning_rate": 3.9695748190719454e-05,
      "loss": 0.9734,
      "step": 15500
    },
    {
      "epoch": 0.6186019595713687,
      "eval_loss": 0.9112229347229004,
      "eval_runtime": 528.1186,
      "eval_samples_per_second": 11.861,
      "eval_steps_per_second": 11.861,
      "step": 15500
    },
    {
      "epoch": 0.6225929399557001,
      "grad_norm": 0.8715848326683044,
      "learning_rate": 3.962923052362707e-05,
      "loss": 0.8946,
      "step": 15600
    },
    {
      "epoch": 0.6265839203400315,
      "grad_norm": 2.5102744102478027,
      "learning_rate": 3.95627128565347e-05,
      "loss": 0.9572,
      "step": 15700
    },
    {
      "epoch": 0.630574900724363,
      "grad_norm": 3.7873787879943848,
      "learning_rate": 3.949619518944232e-05,
      "loss": 0.9419,
      "step": 15800
    },
    {
      "epoch": 0.6345658811086944,
      "grad_norm": 3.1443581581115723,
      "learning_rate": 3.942967752234994e-05,
      "loss": 0.9374,
      "step": 15900
    },
    {
      "epoch": 0.6385568614930257,
      "grad_norm": 2.8073360919952393,
      "learning_rate": 3.936315985525756e-05,
      "loss": 0.909,
      "step": 16000
    },
    {
      "epoch": 0.6385568614930257,
      "eval_loss": 0.9076576232910156,
      "eval_runtime": 542.0311,
      "eval_samples_per_second": 11.557,
      "eval_steps_per_second": 11.557,
      "step": 16000
    },
    {
      "epoch": 0.6425478418773571,
      "grad_norm": 3.226564884185791,
      "learning_rate": 3.929664218816518e-05,
      "loss": 0.9733,
      "step": 16100
    },
    {
      "epoch": 0.6465388222616886,
      "grad_norm": 3.767603635787964,
      "learning_rate": 3.92301245210728e-05,
      "loss": 0.9545,
      "step": 16200
    },
    {
      "epoch": 0.65052980264602,
      "grad_norm": 2.6651179790496826,
      "learning_rate": 3.9163606853980415e-05,
      "loss": 0.9894,
      "step": 16300
    },
    {
      "epoch": 0.6545207830303514,
      "grad_norm": 3.5687990188598633,
      "learning_rate": 3.909708918688804e-05,
      "loss": 0.9531,
      "step": 16400
    },
    {
      "epoch": 0.6585117634146829,
      "grad_norm": 2.5598034858703613,
      "learning_rate": 3.903057151979566e-05,
      "loss": 0.9651,
      "step": 16500
    },
    {
      "epoch": 0.6585117634146829,
      "eval_loss": 0.9031058549880981,
      "eval_runtime": 427.199,
      "eval_samples_per_second": 14.663,
      "eval_steps_per_second": 14.663,
      "step": 16500
    },
    {
      "epoch": 0.6625027437990142,
      "grad_norm": 2.8277618885040283,
      "learning_rate": 3.8964053852703284e-05,
      "loss": 0.9839,
      "step": 16600
    },
    {
      "epoch": 0.6664937241833456,
      "grad_norm": 2.6865103244781494,
      "learning_rate": 3.88975361856109e-05,
      "loss": 1.0219,
      "step": 16700
    },
    {
      "epoch": 0.6704847045676771,
      "grad_norm": 1.8047250509262085,
      "learning_rate": 3.883101851851852e-05,
      "loss": 0.9308,
      "step": 16800
    },
    {
      "epoch": 0.6744756849520085,
      "grad_norm": 4.118173122406006,
      "learning_rate": 3.876450085142614e-05,
      "loss": 0.934,
      "step": 16900
    },
    {
      "epoch": 0.6784666653363399,
      "grad_norm": 3.0656044483184814,
      "learning_rate": 3.869798318433376e-05,
      "loss": 0.9292,
      "step": 17000
    },
    {
      "epoch": 0.6784666653363399,
      "eval_loss": 0.902349054813385,
      "eval_runtime": 415.6454,
      "eval_samples_per_second": 15.071,
      "eval_steps_per_second": 15.071,
      "step": 17000
    },
    {
      "epoch": 0.6824576457206712,
      "grad_norm": 0.9649878144264221,
      "learning_rate": 3.863146551724138e-05,
      "loss": 0.9564,
      "step": 17100
    },
    {
      "epoch": 0.6864486261050027,
      "grad_norm": 3.51804256439209,
      "learning_rate": 3.8564947850149e-05,
      "loss": 0.9644,
      "step": 17200
    },
    {
      "epoch": 0.6904396064893341,
      "grad_norm": 3.3035888671875,
      "learning_rate": 3.849843018305662e-05,
      "loss": 0.9401,
      "step": 17300
    },
    {
      "epoch": 0.6944305868736655,
      "grad_norm": 2.707153558731079,
      "learning_rate": 3.843191251596424e-05,
      "loss": 0.9417,
      "step": 17400
    },
    {
      "epoch": 0.698421567257997,
      "grad_norm": 2.651494026184082,
      "learning_rate": 3.836539484887186e-05,
      "loss": 0.8355,
      "step": 17500
    },
    {
      "epoch": 0.698421567257997,
      "eval_loss": 0.8982594609260559,
      "eval_runtime": 407.2676,
      "eval_samples_per_second": 15.381,
      "eval_steps_per_second": 15.381,
      "step": 17500
    },
    {
      "epoch": 0.7024125476423283,
      "grad_norm": 3.351055145263672,
      "learning_rate": 3.829887718177948e-05,
      "loss": 0.9637,
      "step": 17600
    },
    {
      "epoch": 0.7064035280266597,
      "grad_norm": 3.349388837814331,
      "learning_rate": 3.823235951468711e-05,
      "loss": 0.8974,
      "step": 17700
    },
    {
      "epoch": 0.7103945084109912,
      "grad_norm": 3.123457908630371,
      "learning_rate": 3.8165841847594725e-05,
      "loss": 0.9283,
      "step": 17800
    },
    {
      "epoch": 0.7143854887953226,
      "grad_norm": 3.572864532470703,
      "learning_rate": 3.8099324180502344e-05,
      "loss": 0.9631,
      "step": 17900
    },
    {
      "epoch": 0.718376469179654,
      "grad_norm": 2.6278514862060547,
      "learning_rate": 3.803280651340996e-05,
      "loss": 0.9298,
      "step": 18000
    },
    {
      "epoch": 0.718376469179654,
      "eval_loss": 0.8954753279685974,
      "eval_runtime": 400.0356,
      "eval_samples_per_second": 15.659,
      "eval_steps_per_second": 15.659,
      "step": 18000
    },
    {
      "epoch": 0.7223674495639854,
      "grad_norm": 3.341151475906372,
      "learning_rate": 3.796695402298851e-05,
      "loss": 0.9412,
      "step": 18100
    },
    {
      "epoch": 0.7263584299483168,
      "grad_norm": 2.6397511959075928,
      "learning_rate": 3.790043635589613e-05,
      "loss": 0.9608,
      "step": 18200
    },
    {
      "epoch": 0.7303494103326482,
      "grad_norm": 3.4382760524749756,
      "learning_rate": 3.783391868880375e-05,
      "loss": 0.9143,
      "step": 18300
    },
    {
      "epoch": 0.7343403907169797,
      "grad_norm": 3.702690362930298,
      "learning_rate": 3.776740102171137e-05,
      "loss": 0.9415,
      "step": 18400
    },
    {
      "epoch": 0.7383313711013111,
      "grad_norm": 3.609015464782715,
      "learning_rate": 3.770088335461899e-05,
      "loss": 0.9524,
      "step": 18500
    },
    {
      "epoch": 0.7383313711013111,
      "eval_loss": 0.8891705870628357,
      "eval_runtime": 404.7582,
      "eval_samples_per_second": 15.476,
      "eval_steps_per_second": 15.476,
      "step": 18500
    },
    {
      "epoch": 0.7423223514856424,
      "grad_norm": 3.0880985260009766,
      "learning_rate": 3.7634365687526605e-05,
      "loss": 0.9895,
      "step": 18600
    },
    {
      "epoch": 0.7463133318699738,
      "grad_norm": 3.48122501373291,
      "learning_rate": 3.7567848020434224e-05,
      "loss": 0.8927,
      "step": 18700
    },
    {
      "epoch": 0.7503043122543053,
      "grad_norm": 3.144608736038208,
      "learning_rate": 3.750133035334185e-05,
      "loss": 0.9528,
      "step": 18800
    },
    {
      "epoch": 0.7542952926386367,
      "grad_norm": 2.675233840942383,
      "learning_rate": 3.7434812686249474e-05,
      "loss": 0.9663,
      "step": 18900
    },
    {
      "epoch": 0.7582862730229681,
      "grad_norm": 1.8746250867843628,
      "learning_rate": 3.736829501915709e-05,
      "loss": 0.9023,
      "step": 19000
    },
    {
      "epoch": 0.7582862730229681,
      "eval_loss": 0.8868353366851807,
      "eval_runtime": 412.8111,
      "eval_samples_per_second": 15.174,
      "eval_steps_per_second": 15.174,
      "step": 19000
    },
    {
      "epoch": 0.7622772534072995,
      "grad_norm": 3.5809249877929688,
      "learning_rate": 3.730177735206471e-05,
      "loss": 0.9421,
      "step": 19100
    },
    {
      "epoch": 0.7662682337916309,
      "grad_norm": 2.028297185897827,
      "learning_rate": 3.723525968497233e-05,
      "loss": 0.9518,
      "step": 19200
    },
    {
      "epoch": 0.7702592141759623,
      "grad_norm": 2.456278085708618,
      "learning_rate": 3.716874201787995e-05,
      "loss": 0.9209,
      "step": 19300
    },
    {
      "epoch": 0.7742501945602938,
      "grad_norm": 2.8736586570739746,
      "learning_rate": 3.710222435078757e-05,
      "loss": 0.9157,
      "step": 19400
    },
    {
      "epoch": 0.7782411749446252,
      "grad_norm": 1.6782472133636475,
      "learning_rate": 3.703570668369519e-05,
      "loss": 0.9503,
      "step": 19500
    },
    {
      "epoch": 0.7782411749446252,
      "eval_loss": 0.88481205701828,
      "eval_runtime": 406.1804,
      "eval_samples_per_second": 15.422,
      "eval_steps_per_second": 15.422,
      "step": 19500
    },
    {
      "epoch": 0.7822321553289565,
      "grad_norm": 2.9865169525146484,
      "learning_rate": 3.696918901660281e-05,
      "loss": 0.9193,
      "step": 19600
    },
    {
      "epoch": 0.786223135713288,
      "grad_norm": 3.4268107414245605,
      "learning_rate": 3.6902671349510435e-05,
      "loss": 0.936,
      "step": 19700
    },
    {
      "epoch": 0.7902141160976194,
      "grad_norm": 3.3775665760040283,
      "learning_rate": 3.683615368241805e-05,
      "loss": 0.9108,
      "step": 19800
    },
    {
      "epoch": 0.7942050964819508,
      "grad_norm": 3.441525936126709,
      "learning_rate": 3.676963601532567e-05,
      "loss": 0.9484,
      "step": 19900
    },
    {
      "epoch": 0.7981960768662822,
      "grad_norm": 3.306699514389038,
      "learning_rate": 3.67031183482333e-05,
      "loss": 0.95,
      "step": 20000
    },
    {
      "epoch": 0.7981960768662822,
      "eval_loss": 0.8799207210540771,
      "eval_runtime": 407.4173,
      "eval_samples_per_second": 15.375,
      "eval_steps_per_second": 15.375,
      "step": 20000
    },
    {
      "epoch": 0.8021870572506136,
      "grad_norm": 2.5622260570526123,
      "learning_rate": 3.6637265857811834e-05,
      "loss": 0.9601,
      "step": 20100
    },
    {
      "epoch": 0.806178037634945,
      "grad_norm": 3.25874400138855,
      "learning_rate": 3.657074819071945e-05,
      "loss": 0.9363,
      "step": 20200
    },
    {
      "epoch": 0.8101690180192764,
      "grad_norm": 2.268873691558838,
      "learning_rate": 3.650423052362708e-05,
      "loss": 0.9351,
      "step": 20300
    },
    {
      "epoch": 0.8141599984036079,
      "grad_norm": 1.3935811519622803,
      "learning_rate": 3.6437712856534696e-05,
      "loss": 0.9401,
      "step": 20400
    },
    {
      "epoch": 0.8181509787879393,
      "grad_norm": 2.1746408939361572,
      "learning_rate": 3.637119518944232e-05,
      "loss": 0.9147,
      "step": 20500
    },
    {
      "epoch": 0.8181509787879393,
      "eval_loss": 0.8777870535850525,
      "eval_runtime": 411.1534,
      "eval_samples_per_second": 15.235,
      "eval_steps_per_second": 15.235,
      "step": 20500
    },
    {
      "epoch": 0.8221419591722706,
      "grad_norm": 2.734199047088623,
      "learning_rate": 3.630467752234994e-05,
      "loss": 0.9541,
      "step": 20600
    },
    {
      "epoch": 0.826132939556602,
      "grad_norm": 1.2586443424224854,
      "learning_rate": 3.623815985525756e-05,
      "loss": 0.9746,
      "step": 20700
    },
    {
      "epoch": 0.8301239199409335,
      "grad_norm": 2.894620180130005,
      "learning_rate": 3.617164218816518e-05,
      "loss": 0.9702,
      "step": 20800
    },
    {
      "epoch": 0.8341149003252649,
      "grad_norm": 3.552426815032959,
      "learning_rate": 3.6105124521072795e-05,
      "loss": 0.9327,
      "step": 20900
    },
    {
      "epoch": 0.8381058807095964,
      "grad_norm": 2.1058056354522705,
      "learning_rate": 3.6038606853980414e-05,
      "loss": 0.9534,
      "step": 21000
    },
    {
      "epoch": 0.8381058807095964,
      "eval_loss": 0.8731666207313538,
      "eval_runtime": 405.4995,
      "eval_samples_per_second": 15.448,
      "eval_steps_per_second": 15.448,
      "step": 21000
    },
    {
      "epoch": 0.8420968610939277,
      "grad_norm": 2.90907883644104,
      "learning_rate": 3.597208918688804e-05,
      "loss": 0.9419,
      "step": 21100
    },
    {
      "epoch": 0.8460878414782591,
      "grad_norm": 1.8298548460006714,
      "learning_rate": 3.5905571519795664e-05,
      "loss": 0.8974,
      "step": 21200
    },
    {
      "epoch": 0.8500788218625905,
      "grad_norm": 7.358861923217773,
      "learning_rate": 3.583905385270328e-05,
      "loss": 0.9297,
      "step": 21300
    },
    {
      "epoch": 0.854069802246922,
      "grad_norm": 2.138087749481201,
      "learning_rate": 3.57725361856109e-05,
      "loss": 0.9568,
      "step": 21400
    },
    {
      "epoch": 0.8580607826312534,
      "grad_norm": 1.2107622623443604,
      "learning_rate": 3.570601851851852e-05,
      "loss": 0.9567,
      "step": 21500
    },
    {
      "epoch": 0.8580607826312534,
      "eval_loss": 0.8695343732833862,
      "eval_runtime": 410.904,
      "eval_samples_per_second": 15.244,
      "eval_steps_per_second": 15.244,
      "step": 21500
    },
    {
      "epoch": 0.8620517630155847,
      "grad_norm": 2.094585657119751,
      "learning_rate": 3.563950085142614e-05,
      "loss": 0.9253,
      "step": 21600
    },
    {
      "epoch": 0.8660427433999162,
      "grad_norm": 2.821871280670166,
      "learning_rate": 3.5572983184333756e-05,
      "loss": 0.9727,
      "step": 21700
    },
    {
      "epoch": 0.8700337237842476,
      "grad_norm": 1.7008811235427856,
      "learning_rate": 3.550646551724138e-05,
      "loss": 0.9433,
      "step": 21800
    },
    {
      "epoch": 0.874024704168579,
      "grad_norm": 2.8889083862304688,
      "learning_rate": 3.5439947850149e-05,
      "loss": 0.9255,
      "step": 21900
    },
    {
      "epoch": 0.8780156845529105,
      "grad_norm": 1.8353734016418457,
      "learning_rate": 3.5374095359727544e-05,
      "loss": 0.9403,
      "step": 22000
    },
    {
      "epoch": 0.8780156845529105,
      "eval_loss": 0.8683957457542419,
      "eval_runtime": 421.6864,
      "eval_samples_per_second": 14.855,
      "eval_steps_per_second": 14.855,
      "step": 22000
    },
    {
      "epoch": 0.8820066649372418,
      "grad_norm": 3.257962703704834,
      "learning_rate": 3.530757769263516e-05,
      "loss": 0.9023,
      "step": 22100
    },
    {
      "epoch": 0.8859976453215732,
      "grad_norm": 2.6668968200683594,
      "learning_rate": 3.524106002554279e-05,
      "loss": 0.9614,
      "step": 22200
    },
    {
      "epoch": 0.8899886257059046,
      "grad_norm": 3.021456241607666,
      "learning_rate": 3.5174542358450406e-05,
      "loss": 0.9307,
      "step": 22300
    },
    {
      "epoch": 0.8939796060902361,
      "grad_norm": 2.69997501373291,
      "learning_rate": 3.5108024691358025e-05,
      "loss": 0.9189,
      "step": 22400
    },
    {
      "epoch": 0.8979705864745675,
      "grad_norm": 3.154231309890747,
      "learning_rate": 3.504150702426564e-05,
      "loss": 0.919,
      "step": 22500
    },
    {
      "epoch": 0.8979705864745675,
      "eval_loss": 0.8672598600387573,
      "eval_runtime": 411.2319,
      "eval_samples_per_second": 15.232,
      "eval_steps_per_second": 15.232,
      "step": 22500
    },
    {
      "epoch": 0.9019615668588988,
      "grad_norm": 2.6928069591522217,
      "learning_rate": 3.497498935717327e-05,
      "loss": 0.9323,
      "step": 22600
    },
    {
      "epoch": 0.9059525472432303,
      "grad_norm": 2.4564545154571533,
      "learning_rate": 3.4908471690080887e-05,
      "loss": 0.9277,
      "step": 22700
    },
    {
      "epoch": 0.9099435276275617,
      "grad_norm": 2.8209967613220215,
      "learning_rate": 3.484195402298851e-05,
      "loss": 0.9515,
      "step": 22800
    },
    {
      "epoch": 0.9139345080118931,
      "grad_norm": 3.493375301361084,
      "learning_rate": 3.477543635589613e-05,
      "loss": 0.9112,
      "step": 22900
    },
    {
      "epoch": 0.9179254883962246,
      "grad_norm": 2.5519585609436035,
      "learning_rate": 3.470891868880375e-05,
      "loss": 0.9425,
      "step": 23000
    },
    {
      "epoch": 0.9179254883962246,
      "eval_loss": 0.8652753233909607,
      "eval_runtime": 415.1534,
      "eval_samples_per_second": 15.088,
      "eval_steps_per_second": 15.088,
      "step": 23000
    },
    {
      "epoch": 0.921916468780556,
      "grad_norm": 3.0991806983947754,
      "learning_rate": 3.464240102171137e-05,
      "loss": 0.8708,
      "step": 23100
    },
    {
      "epoch": 0.9259074491648873,
      "grad_norm": 2.1286988258361816,
      "learning_rate": 3.4575883354618985e-05,
      "loss": 0.9153,
      "step": 23200
    },
    {
      "epoch": 0.9298984295492188,
      "grad_norm": 2.859429121017456,
      "learning_rate": 3.4509365687526604e-05,
      "loss": 0.8932,
      "step": 23300
    },
    {
      "epoch": 0.9338894099335502,
      "grad_norm": 2.955625057220459,
      "learning_rate": 3.444284802043423e-05,
      "loss": 0.9094,
      "step": 23400
    },
    {
      "epoch": 0.9378803903178816,
      "grad_norm": 3.1708810329437256,
      "learning_rate": 3.4376330353341854e-05,
      "loss": 0.9022,
      "step": 23500
    },
    {
      "epoch": 0.9378803903178816,
      "eval_loss": 0.8638924360275269,
      "eval_runtime": 422.4483,
      "eval_samples_per_second": 14.828,
      "eval_steps_per_second": 14.828,
      "step": 23500
    },
    {
      "epoch": 0.941871370702213,
      "grad_norm": 2.9772109985351562,
      "learning_rate": 3.430981268624947e-05,
      "loss": 0.9684,
      "step": 23600
    },
    {
      "epoch": 0.9458623510865444,
      "grad_norm": 3.1483731269836426,
      "learning_rate": 3.424329501915709e-05,
      "loss": 0.8954,
      "step": 23700
    },
    {
      "epoch": 0.9498533314708758,
      "grad_norm": 3.5204076766967773,
      "learning_rate": 3.417677735206471e-05,
      "loss": 0.9542,
      "step": 23800
    },
    {
      "epoch": 0.9538443118552072,
      "grad_norm": 2.8973965644836426,
      "learning_rate": 3.411025968497233e-05,
      "loss": 0.8838,
      "step": 23900
    },
    {
      "epoch": 0.9578352922395387,
      "grad_norm": 3.1436402797698975,
      "learning_rate": 3.4043742017879946e-05,
      "loss": 0.9109,
      "step": 24000
    },
    {
      "epoch": 0.9578352922395387,
      "eval_loss": 0.8579012751579285,
      "eval_runtime": 428.518,
      "eval_samples_per_second": 14.618,
      "eval_steps_per_second": 14.618,
      "step": 24000
    },
    {
      "epoch": 0.9618262726238701,
      "grad_norm": 14.387167930603027,
      "learning_rate": 3.397722435078757e-05,
      "loss": 0.868,
      "step": 24100
    },
    {
      "epoch": 0.9658172530082014,
      "grad_norm": 2.6405506134033203,
      "learning_rate": 3.391070668369519e-05,
      "loss": 0.9128,
      "step": 24200
    },
    {
      "epoch": 0.9698082333925329,
      "grad_norm": 2.232375144958496,
      "learning_rate": 3.3844189016602815e-05,
      "loss": 0.8999,
      "step": 24300
    },
    {
      "epoch": 0.9737992137768643,
      "grad_norm": 4.009490966796875,
      "learning_rate": 3.3777671349510433e-05,
      "loss": 0.8951,
      "step": 24400
    },
    {
      "epoch": 0.9777901941611957,
      "grad_norm": 3.438755512237549,
      "learning_rate": 3.371115368241805e-05,
      "loss": 0.9307,
      "step": 24500
    },
    {
      "epoch": 0.9777901941611957,
      "eval_loss": 0.856128990650177,
      "eval_runtime": 419.6917,
      "eval_samples_per_second": 14.925,
      "eval_steps_per_second": 14.925,
      "step": 24500
    },
    {
      "epoch": 0.9817811745455272,
      "grad_norm": 1.3997957706451416,
      "learning_rate": 3.364463601532567e-05,
      "loss": 0.9177,
      "step": 24600
    },
    {
      "epoch": 0.9857721549298585,
      "grad_norm": 3.0660223960876465,
      "learning_rate": 3.3578118348233295e-05,
      "loss": 0.9434,
      "step": 24700
    },
    {
      "epoch": 0.9897631353141899,
      "grad_norm": 3.264888048171997,
      "learning_rate": 3.3511600681140914e-05,
      "loss": 0.9378,
      "step": 24800
    },
    {
      "epoch": 0.9937541156985213,
      "grad_norm": 2.515141725540161,
      "learning_rate": 3.344508301404853e-05,
      "loss": 0.946,
      "step": 24900
    },
    {
      "epoch": 0.9977450960828528,
      "grad_norm": 2.8283209800720215,
      "learning_rate": 3.337856534695615e-05,
      "loss": 0.8261,
      "step": 25000
    },
    {
      "epoch": 0.9977450960828528,
      "eval_loss": 0.8558309674263,
      "eval_runtime": 411.3908,
      "eval_samples_per_second": 15.226,
      "eval_steps_per_second": 15.226,
      "step": 25000
    },
    {
      "epoch": 1.0017161215652626,
      "grad_norm": 2.8238916397094727,
      "learning_rate": 3.3312047679863776e-05,
      "loss": 0.8465,
      "step": 25100
    },
    {
      "epoch": 1.005707101949594,
      "grad_norm": 2.2057836055755615,
      "learning_rate": 3.3245530012771394e-05,
      "loss": 0.9014,
      "step": 25200
    },
    {
      "epoch": 1.0096980823339252,
      "grad_norm": 2.2484819889068604,
      "learning_rate": 3.317901234567901e-05,
      "loss": 0.9082,
      "step": 25300
    },
    {
      "epoch": 1.0136890627182567,
      "grad_norm": 2.5985424518585205,
      "learning_rate": 3.311249467858664e-05,
      "loss": 0.8929,
      "step": 25400
    },
    {
      "epoch": 1.017680043102588,
      "grad_norm": 2.702775716781616,
      "learning_rate": 3.3045977011494256e-05,
      "loss": 0.9225,
      "step": 25500
    },
    {
      "epoch": 1.017680043102588,
      "eval_loss": 0.8538689017295837,
      "eval_runtime": 423.4774,
      "eval_samples_per_second": 14.792,
      "eval_steps_per_second": 14.792,
      "step": 25500
    },
    {
      "epoch": 1.0216710234869195,
      "grad_norm": 3.3532464504241943,
      "learning_rate": 3.2979459344401875e-05,
      "loss": 0.9173,
      "step": 25600
    },
    {
      "epoch": 1.025662003871251,
      "grad_norm": 2.990546703338623,
      "learning_rate": 3.291294167730949e-05,
      "loss": 0.8989,
      "step": 25700
    },
    {
      "epoch": 1.0296529842555824,
      "grad_norm": 2.4527626037597656,
      "learning_rate": 3.284642401021711e-05,
      "loss": 0.8437,
      "step": 25800
    },
    {
      "epoch": 1.0336439646399138,
      "grad_norm": 2.567833423614502,
      "learning_rate": 3.277990634312474e-05,
      "loss": 0.8945,
      "step": 25900
    },
    {
      "epoch": 1.0376349450242452,
      "grad_norm": 2.042468309402466,
      "learning_rate": 3.2713388676032355e-05,
      "loss": 0.8797,
      "step": 26000
    },
    {
      "epoch": 1.0376349450242452,
      "eval_loss": 0.8536670804023743,
      "eval_runtime": 425.4072,
      "eval_samples_per_second": 14.725,
      "eval_steps_per_second": 14.725,
      "step": 26000
    },
    {
      "epoch": 1.0416259254085767,
      "grad_norm": 3.0810182094573975,
      "learning_rate": 3.26475361856109e-05,
      "loss": 0.8367,
      "step": 26100
    },
    {
      "epoch": 1.0456169057929081,
      "grad_norm": 3.1987974643707275,
      "learning_rate": 3.258101851851852e-05,
      "loss": 0.8874,
      "step": 26200
    },
    {
      "epoch": 1.0496078861772395,
      "grad_norm": 1.9290220737457275,
      "learning_rate": 3.2514500851426136e-05,
      "loss": 0.8678,
      "step": 26300
    },
    {
      "epoch": 1.0535988665615708,
      "grad_norm": 2.402895927429199,
      "learning_rate": 3.2447983184333755e-05,
      "loss": 0.875,
      "step": 26400
    },
    {
      "epoch": 1.0575898469459022,
      "grad_norm": 2.6331100463867188,
      "learning_rate": 3.238146551724138e-05,
      "loss": 0.888,
      "step": 26500
    },
    {
      "epoch": 1.0575898469459022,
      "eval_loss": 0.8491957783699036,
      "eval_runtime": 415.8888,
      "eval_samples_per_second": 15.062,
      "eval_steps_per_second": 15.062,
      "step": 26500
    },
    {
      "epoch": 1.0615808273302336,
      "grad_norm": 2.1018712520599365,
      "learning_rate": 3.2314947850149005e-05,
      "loss": 0.853,
      "step": 26600
    },
    {
      "epoch": 1.065571807714565,
      "grad_norm": 2.8848822116851807,
      "learning_rate": 3.2248430183056623e-05,
      "loss": 0.8415,
      "step": 26700
    },
    {
      "epoch": 1.0695627880988965,
      "grad_norm": 1.642582893371582,
      "learning_rate": 3.218191251596424e-05,
      "loss": 0.8836,
      "step": 26800
    },
    {
      "epoch": 1.073553768483228,
      "grad_norm": 3.101557493209839,
      "learning_rate": 3.211539484887186e-05,
      "loss": 0.8305,
      "step": 26900
    },
    {
      "epoch": 1.0775447488675594,
      "grad_norm": 3.1877615451812744,
      "learning_rate": 3.204887718177948e-05,
      "loss": 0.8553,
      "step": 27000
    },
    {
      "epoch": 1.0775447488675594,
      "eval_loss": 0.8518254160881042,
      "eval_runtime": 416.0446,
      "eval_samples_per_second": 15.056,
      "eval_steps_per_second": 15.056,
      "step": 27000
    },
    {
      "epoch": 1.0815357292518908,
      "grad_norm": 2.1097471714019775,
      "learning_rate": 3.1982359514687104e-05,
      "loss": 0.8964,
      "step": 27100
    },
    {
      "epoch": 1.0855267096362222,
      "grad_norm": 1.8912872076034546,
      "learning_rate": 3.191584184759472e-05,
      "loss": 0.8312,
      "step": 27200
    },
    {
      "epoch": 1.0895176900205537,
      "grad_norm": 2.9403984546661377,
      "learning_rate": 3.184932418050234e-05,
      "loss": 0.8976,
      "step": 27300
    },
    {
      "epoch": 1.0935086704048849,
      "grad_norm": 2.269333600997925,
      "learning_rate": 3.1782806513409966e-05,
      "loss": 0.8518,
      "step": 27400
    },
    {
      "epoch": 1.0974996507892163,
      "grad_norm": 2.513744354248047,
      "learning_rate": 3.1716288846317584e-05,
      "loss": 0.8773,
      "step": 27500
    },
    {
      "epoch": 1.0974996507892163,
      "eval_loss": 0.8469676375389099,
      "eval_runtime": 415.3737,
      "eval_samples_per_second": 15.08,
      "eval_steps_per_second": 15.08,
      "step": 27500
    },
    {
      "epoch": 1.1014906311735477,
      "grad_norm": 3.081252336502075,
      "learning_rate": 3.16497711792252e-05,
      "loss": 0.8684,
      "step": 27600
    },
    {
      "epoch": 1.1054816115578792,
      "grad_norm": 3.126840353012085,
      "learning_rate": 3.158325351213283e-05,
      "loss": 0.8916,
      "step": 27700
    },
    {
      "epoch": 1.1094725919422106,
      "grad_norm": 3.293458938598633,
      "learning_rate": 3.1516735845040446e-05,
      "loss": 0.8507,
      "step": 27800
    },
    {
      "epoch": 1.113463572326542,
      "grad_norm": 3.096238374710083,
      "learning_rate": 3.1450218177948065e-05,
      "loss": 0.9099,
      "step": 27900
    },
    {
      "epoch": 1.1174545527108735,
      "grad_norm": 2.1968462467193604,
      "learning_rate": 3.138370051085568e-05,
      "loss": 0.8883,
      "step": 28000
    },
    {
      "epoch": 1.1174545527108735,
      "eval_loss": 0.8451356291770935,
      "eval_runtime": 404.6634,
      "eval_samples_per_second": 15.48,
      "eval_steps_per_second": 15.48,
      "step": 28000
    },
    {
      "epoch": 1.121445533095205,
      "grad_norm": 2.3176381587982178,
      "learning_rate": 3.131784802043423e-05,
      "loss": 0.8246,
      "step": 28100
    },
    {
      "epoch": 1.1254365134795363,
      "grad_norm": 3.1964359283447266,
      "learning_rate": 3.125133035334185e-05,
      "loss": 0.8495,
      "step": 28200
    },
    {
      "epoch": 1.1294274938638678,
      "grad_norm": 2.960085391998291,
      "learning_rate": 3.118481268624947e-05,
      "loss": 0.8735,
      "step": 28300
    },
    {
      "epoch": 1.1334184742481992,
      "grad_norm": 2.625728130340576,
      "learning_rate": 3.111829501915709e-05,
      "loss": 0.864,
      "step": 28400
    },
    {
      "epoch": 1.1374094546325304,
      "grad_norm": 2.6240432262420654,
      "learning_rate": 3.105177735206471e-05,
      "loss": 0.8587,
      "step": 28500
    },
    {
      "epoch": 1.1374094546325304,
      "eval_loss": 0.8435544967651367,
      "eval_runtime": 411.2303,
      "eval_samples_per_second": 15.232,
      "eval_steps_per_second": 15.232,
      "step": 28500
    },
    {
      "epoch": 1.1414004350168618,
      "grad_norm": 1.921344518661499,
      "learning_rate": 3.0985259684972326e-05,
      "loss": 0.9117,
      "step": 28600
    },
    {
      "epoch": 1.1453914154011933,
      "grad_norm": 3.113684892654419,
      "learning_rate": 3.0918742017879945e-05,
      "loss": 0.876,
      "step": 28700
    },
    {
      "epoch": 1.1493823957855247,
      "grad_norm": 2.6921029090881348,
      "learning_rate": 3.085222435078757e-05,
      "loss": 0.8847,
      "step": 28800
    },
    {
      "epoch": 1.1533733761698561,
      "grad_norm": 2.7506022453308105,
      "learning_rate": 3.0785706683695195e-05,
      "loss": 0.8903,
      "step": 28900
    },
    {
      "epoch": 1.1573643565541876,
      "grad_norm": 3.407259464263916,
      "learning_rate": 3.0719189016602814e-05,
      "loss": 0.8927,
      "step": 29000
    },
    {
      "epoch": 1.1573643565541876,
      "eval_loss": 0.8425205945968628,
      "eval_runtime": 417.4406,
      "eval_samples_per_second": 15.006,
      "eval_steps_per_second": 15.006,
      "step": 29000
    },
    {
      "epoch": 1.161355336938519,
      "grad_norm": 2.570735216140747,
      "learning_rate": 3.065267134951043e-05,
      "loss": 0.8685,
      "step": 29100
    },
    {
      "epoch": 1.1653463173228504,
      "grad_norm": 2.9107906818389893,
      "learning_rate": 3.058615368241805e-05,
      "loss": 0.9048,
      "step": 29200
    },
    {
      "epoch": 1.1693372977071816,
      "grad_norm": 3.047741174697876,
      "learning_rate": 3.051963601532567e-05,
      "loss": 0.878,
      "step": 29300
    },
    {
      "epoch": 1.173328278091513,
      "grad_norm": 2.386192560195923,
      "learning_rate": 3.0453118348233294e-05,
      "loss": 0.8621,
      "step": 29400
    },
    {
      "epoch": 1.1773192584758445,
      "grad_norm": 2.130801200866699,
      "learning_rate": 3.0386600681140916e-05,
      "loss": 0.8842,
      "step": 29500
    },
    {
      "epoch": 1.1773192584758445,
      "eval_loss": 0.8394293785095215,
      "eval_runtime": 410.3049,
      "eval_samples_per_second": 15.267,
      "eval_steps_per_second": 15.267,
      "step": 29500
    },
    {
      "epoch": 1.181310238860176,
      "grad_norm": 0.8260827660560608,
      "learning_rate": 3.0320083014048534e-05,
      "loss": 0.8679,
      "step": 29600
    },
    {
      "epoch": 1.1853012192445074,
      "grad_norm": 2.66226863861084,
      "learning_rate": 3.0253565346956153e-05,
      "loss": 0.8368,
      "step": 29700
    },
    {
      "epoch": 1.1892921996288388,
      "grad_norm": 2.985400915145874,
      "learning_rate": 3.018704767986377e-05,
      "loss": 0.8692,
      "step": 29800
    },
    {
      "epoch": 1.1932831800131702,
      "grad_norm": 2.1856300830841064,
      "learning_rate": 3.0120530012771393e-05,
      "loss": 0.874,
      "step": 29900
    },
    {
      "epoch": 1.1972741603975017,
      "grad_norm": 3.314323902130127,
      "learning_rate": 3.005401234567901e-05,
      "loss": 0.8864,
      "step": 30000
    },
    {
      "epoch": 1.1972741603975017,
      "eval_loss": 0.8389289975166321,
      "eval_runtime": 410.2179,
      "eval_samples_per_second": 15.27,
      "eval_steps_per_second": 15.27,
      "step": 30000
    },
    {
      "epoch": 1.201265140781833,
      "grad_norm": 1.387070894241333,
      "learning_rate": 2.998815985525756e-05,
      "loss": 0.8813,
      "step": 30100
    },
    {
      "epoch": 1.2052561211661645,
      "grad_norm": 1.8101025819778442,
      "learning_rate": 2.9921642188165177e-05,
      "loss": 0.8586,
      "step": 30200
    },
    {
      "epoch": 1.209247101550496,
      "grad_norm": 2.329462766647339,
      "learning_rate": 2.9855124521072796e-05,
      "loss": 0.887,
      "step": 30300
    },
    {
      "epoch": 1.2132380819348274,
      "grad_norm": 3.031726360321045,
      "learning_rate": 2.9788606853980418e-05,
      "loss": 0.8335,
      "step": 30400
    },
    {
      "epoch": 1.2172290623191586,
      "grad_norm": 4.65815544128418,
      "learning_rate": 2.9722754363558962e-05,
      "loss": 0.9407,
      "step": 30500
    },
    {
      "epoch": 1.2172290623191586,
      "eval_loss": 0.8386340141296387,
      "eval_runtime": 412.0009,
      "eval_samples_per_second": 15.204,
      "eval_steps_per_second": 15.204,
      "step": 30500
    },
    {
      "epoch": 1.22122004270349,
      "grad_norm": 2.5409364700317383,
      "learning_rate": 2.9656236696466584e-05,
      "loss": 0.8461,
      "step": 30600
    },
    {
      "epoch": 1.2252110230878215,
      "grad_norm": 2.5956180095672607,
      "learning_rate": 2.9589719029374202e-05,
      "loss": 0.8951,
      "step": 30700
    },
    {
      "epoch": 1.229202003472153,
      "grad_norm": 2.7465226650238037,
      "learning_rate": 2.952320136228182e-05,
      "loss": 0.8661,
      "step": 30800
    },
    {
      "epoch": 1.2331929838564843,
      "grad_norm": 2.655946731567383,
      "learning_rate": 2.9456683695189446e-05,
      "loss": 0.8512,
      "step": 30900
    },
    {
      "epoch": 1.2371839642408158,
      "grad_norm": 3.013169288635254,
      "learning_rate": 2.9390166028097064e-05,
      "loss": 0.8526,
      "step": 31000
    },
    {
      "epoch": 1.2371839642408158,
      "eval_loss": 0.8366705179214478,
      "eval_runtime": 415.3204,
      "eval_samples_per_second": 15.082,
      "eval_steps_per_second": 15.082,
      "step": 31000
    },
    {
      "epoch": 1.2411749446251472,
      "grad_norm": 2.3730390071868896,
      "learning_rate": 2.9323648361004686e-05,
      "loss": 0.88,
      "step": 31100
    },
    {
      "epoch": 1.2451659250094786,
      "grad_norm": 2.8099799156188965,
      "learning_rate": 2.9257130693912305e-05,
      "loss": 0.8519,
      "step": 31200
    },
    {
      "epoch": 1.24915690539381,
      "grad_norm": 2.5758767127990723,
      "learning_rate": 2.9190613026819923e-05,
      "loss": 0.8622,
      "step": 31300
    },
    {
      "epoch": 1.2531478857781413,
      "grad_norm": 2.928164482116699,
      "learning_rate": 2.9124095359727545e-05,
      "loss": 0.8952,
      "step": 31400
    },
    {
      "epoch": 1.2571388661624727,
      "grad_norm": 2.8101630210876465,
      "learning_rate": 2.9057577692635163e-05,
      "loss": 0.9088,
      "step": 31500
    },
    {
      "epoch": 1.2571388661624727,
      "eval_loss": 0.8347254991531372,
      "eval_runtime": 411.3125,
      "eval_samples_per_second": 15.229,
      "eval_steps_per_second": 15.229,
      "step": 31500
    },
    {
      "epoch": 1.2611298465468042,
      "grad_norm": 2.475611925125122,
      "learning_rate": 2.899106002554279e-05,
      "loss": 0.855,
      "step": 31600
    },
    {
      "epoch": 1.2651208269311356,
      "grad_norm": 2.9386379718780518,
      "learning_rate": 2.8924542358450407e-05,
      "loss": 0.8477,
      "step": 31700
    },
    {
      "epoch": 1.269111807315467,
      "grad_norm": 3.0594606399536133,
      "learning_rate": 2.8858024691358025e-05,
      "loss": 0.8503,
      "step": 31800
    },
    {
      "epoch": 1.2731027876997985,
      "grad_norm": 2.5689761638641357,
      "learning_rate": 2.8791507024265647e-05,
      "loss": 0.9274,
      "step": 31900
    },
    {
      "epoch": 1.2770937680841299,
      "grad_norm": 3.13873028755188,
      "learning_rate": 2.8724989357173265e-05,
      "loss": 0.907,
      "step": 32000
    },
    {
      "epoch": 1.2770937680841299,
      "eval_loss": 0.8354132771492004,
      "eval_runtime": 411.5467,
      "eval_samples_per_second": 15.221,
      "eval_steps_per_second": 15.221,
      "step": 32000
    },
    {
      "epoch": 1.2810847484684613,
      "grad_norm": 3.293349504470825,
      "learning_rate": 2.8658471690080884e-05,
      "loss": 0.8454,
      "step": 32100
    },
    {
      "epoch": 1.2850757288527928,
      "grad_norm": 1.484701156616211,
      "learning_rate": 2.859195402298851e-05,
      "loss": 0.8577,
      "step": 32200
    },
    {
      "epoch": 1.2890667092371242,
      "grad_norm": 2.24655818939209,
      "learning_rate": 2.852543635589613e-05,
      "loss": 0.8937,
      "step": 32300
    },
    {
      "epoch": 1.2930576896214556,
      "grad_norm": 1.9643338918685913,
      "learning_rate": 2.845891868880375e-05,
      "loss": 0.8546,
      "step": 32400
    },
    {
      "epoch": 1.297048670005787,
      "grad_norm": 2.5089364051818848,
      "learning_rate": 2.8392401021711368e-05,
      "loss": 0.8808,
      "step": 32500
    },
    {
      "epoch": 1.297048670005787,
      "eval_loss": 0.8353638052940369,
      "eval_runtime": 411.637,
      "eval_samples_per_second": 15.217,
      "eval_steps_per_second": 15.217,
      "step": 32500
    },
    {
      "epoch": 1.3010396503901183,
      "grad_norm": 2.4622795581817627,
      "learning_rate": 2.8325883354618986e-05,
      "loss": 0.8485,
      "step": 32600
    },
    {
      "epoch": 1.3050306307744497,
      "grad_norm": 2.0035903453826904,
      "learning_rate": 2.8259365687526608e-05,
      "loss": 0.8812,
      "step": 32700
    },
    {
      "epoch": 1.3090216111587811,
      "grad_norm": 3.4279367923736572,
      "learning_rate": 2.8192848020434226e-05,
      "loss": 0.8326,
      "step": 32800
    },
    {
      "epoch": 1.3130125915431126,
      "grad_norm": 2.9591526985168457,
      "learning_rate": 2.812633035334185e-05,
      "loss": 0.8259,
      "step": 32900
    },
    {
      "epoch": 1.317003571927444,
      "grad_norm": 2.4458582401275635,
      "learning_rate": 2.805981268624947e-05,
      "loss": 0.875,
      "step": 33000
    },
    {
      "epoch": 1.317003571927444,
      "eval_loss": 0.8308136463165283,
      "eval_runtime": 410.068,
      "eval_samples_per_second": 15.276,
      "eval_steps_per_second": 15.276,
      "step": 33000
    },
    {
      "epoch": 1.3209945523117754,
      "grad_norm": 3.290972948074341,
      "learning_rate": 2.7993295019157088e-05,
      "loss": 0.8458,
      "step": 33100
    },
    {
      "epoch": 1.3249855326961069,
      "grad_norm": 2.6903326511383057,
      "learning_rate": 2.792677735206471e-05,
      "loss": 0.8669,
      "step": 33200
    },
    {
      "epoch": 1.328976513080438,
      "grad_norm": 3.0533840656280518,
      "learning_rate": 2.786025968497233e-05,
      "loss": 0.8349,
      "step": 33300
    },
    {
      "epoch": 1.3329674934647695,
      "grad_norm": 1.5624499320983887,
      "learning_rate": 2.7793742017879947e-05,
      "loss": 0.8959,
      "step": 33400
    },
    {
      "epoch": 1.336958473849101,
      "grad_norm": 1.6122417449951172,
      "learning_rate": 2.7727224350787572e-05,
      "loss": 0.9037,
      "step": 33500
    },
    {
      "epoch": 1.336958473849101,
      "eval_loss": 0.8309920430183411,
      "eval_runtime": 405.7292,
      "eval_samples_per_second": 15.439,
      "eval_steps_per_second": 15.439,
      "step": 33500
    },
    {
      "epoch": 1.3409494542334324,
      "grad_norm": 1.8630094528198242,
      "learning_rate": 2.7660706683695194e-05,
      "loss": 0.8524,
      "step": 33600
    },
    {
      "epoch": 1.3449404346177638,
      "grad_norm": 3.017784357070923,
      "learning_rate": 2.7594189016602812e-05,
      "loss": 0.8391,
      "step": 33700
    },
    {
      "epoch": 1.3489314150020952,
      "grad_norm": 2.51627254486084,
      "learning_rate": 2.752767134951043e-05,
      "loss": 0.9121,
      "step": 33800
    },
    {
      "epoch": 1.3529223953864267,
      "grad_norm": 3.125725507736206,
      "learning_rate": 2.746115368241805e-05,
      "loss": 0.7921,
      "step": 33900
    },
    {
      "epoch": 1.356913375770758,
      "grad_norm": 3.1680526733398438,
      "learning_rate": 2.739463601532567e-05,
      "loss": 0.8526,
      "step": 34000
    },
    {
      "epoch": 1.356913375770758,
      "eval_loss": 0.8289385437965393,
      "eval_runtime": 404.9388,
      "eval_samples_per_second": 15.469,
      "eval_steps_per_second": 15.469,
      "step": 34000
    },
    {
      "epoch": 1.3609043561550895,
      "grad_norm": 2.8845245838165283,
      "learning_rate": 2.7328118348233296e-05,
      "loss": 0.8614,
      "step": 34100
    },
    {
      "epoch": 1.364895336539421,
      "grad_norm": 3.1227927207946777,
      "learning_rate": 2.7261600681140914e-05,
      "loss": 0.8595,
      "step": 34200
    },
    {
      "epoch": 1.3688863169237524,
      "grad_norm": 2.647397041320801,
      "learning_rate": 2.7195083014048533e-05,
      "loss": 0.8331,
      "step": 34300
    },
    {
      "epoch": 1.3728772973080838,
      "grad_norm": 2.4812936782836914,
      "learning_rate": 2.7128565346956155e-05,
      "loss": 0.8704,
      "step": 34400
    },
    {
      "epoch": 1.3768682776924153,
      "grad_norm": 2.9446940422058105,
      "learning_rate": 2.7062712856534696e-05,
      "loss": 0.8598,
      "step": 34500
    },
    {
      "epoch": 1.3768682776924153,
      "eval_loss": 0.8277904391288757,
      "eval_runtime": 416.563,
      "eval_samples_per_second": 15.037,
      "eval_steps_per_second": 15.037,
      "step": 34500
    },
    {
      "epoch": 1.3808592580767465,
      "grad_norm": 2.927208185195923,
      "learning_rate": 2.699619518944232e-05,
      "loss": 0.8533,
      "step": 34600
    },
    {
      "epoch": 1.384850238461078,
      "grad_norm": 3.0307672023773193,
      "learning_rate": 2.692967752234994e-05,
      "loss": 0.8682,
      "step": 34700
    },
    {
      "epoch": 1.3888412188454093,
      "grad_norm": 2.9868032932281494,
      "learning_rate": 2.6863159855257558e-05,
      "loss": 0.8394,
      "step": 34800
    },
    {
      "epoch": 1.3928321992297408,
      "grad_norm": 2.577044725418091,
      "learning_rate": 2.6796642188165176e-05,
      "loss": 0.8387,
      "step": 34900
    },
    {
      "epoch": 1.3968231796140722,
      "grad_norm": 3.153731107711792,
      "learning_rate": 2.6730124521072798e-05,
      "loss": 0.8354,
      "step": 35000
    },
    {
      "epoch": 1.3968231796140722,
      "eval_loss": 0.8257995843887329,
      "eval_runtime": 406.2616,
      "eval_samples_per_second": 15.419,
      "eval_steps_per_second": 15.419,
      "step": 35000
    },
    {
      "epoch": 1.4008141599984036,
      "grad_norm": 2.996310234069824,
      "learning_rate": 2.6663606853980416e-05,
      "loss": 0.8941,
      "step": 35100
    },
    {
      "epoch": 1.404805140382735,
      "grad_norm": 3.102966547012329,
      "learning_rate": 2.659708918688804e-05,
      "loss": 0.8562,
      "step": 35200
    },
    {
      "epoch": 1.4087961207670665,
      "grad_norm": 2.2894890308380127,
      "learning_rate": 2.653057151979566e-05,
      "loss": 0.827,
      "step": 35300
    },
    {
      "epoch": 1.4127871011513977,
      "grad_norm": 2.723247766494751,
      "learning_rate": 2.646405385270328e-05,
      "loss": 0.8373,
      "step": 35400
    },
    {
      "epoch": 1.4167780815357292,
      "grad_norm": 2.53806471824646,
      "learning_rate": 2.63975361856109e-05,
      "loss": 0.8204,
      "step": 35500
    },
    {
      "epoch": 1.4167780815357292,
      "eval_loss": 0.8235728740692139,
      "eval_runtime": 407.5147,
      "eval_samples_per_second": 15.371,
      "eval_steps_per_second": 15.371,
      "step": 35500
    },
    {
      "epoch": 1.4207690619200606,
      "grad_norm": 2.8054661750793457,
      "learning_rate": 2.633101851851852e-05,
      "loss": 0.8337,
      "step": 35600
    },
    {
      "epoch": 1.424760042304392,
      "grad_norm": 1.7502509355545044,
      "learning_rate": 2.6264500851426137e-05,
      "loss": 0.8796,
      "step": 35700
    },
    {
      "epoch": 1.4287510226887234,
      "grad_norm": 3.5648770332336426,
      "learning_rate": 2.619798318433376e-05,
      "loss": 0.8582,
      "step": 35800
    },
    {
      "epoch": 1.4327420030730549,
      "grad_norm": 2.756697654724121,
      "learning_rate": 2.6131465517241384e-05,
      "loss": 0.8736,
      "step": 35900
    },
    {
      "epoch": 1.4367329834573863,
      "grad_norm": 2.775243043899536,
      "learning_rate": 2.6064947850149002e-05,
      "loss": 0.8127,
      "step": 36000
    },
    {
      "epoch": 1.4367329834573863,
      "eval_loss": 0.8237418532371521,
      "eval_runtime": 401.9846,
      "eval_samples_per_second": 15.583,
      "eval_steps_per_second": 15.583,
      "step": 36000
    },
    {
      "epoch": 1.4407239638417177,
      "grad_norm": 2.6409027576446533,
      "learning_rate": 2.599843018305662e-05,
      "loss": 0.8565,
      "step": 36100
    },
    {
      "epoch": 1.4447149442260492,
      "grad_norm": 2.318873882293701,
      "learning_rate": 2.593191251596424e-05,
      "loss": 0.8714,
      "step": 36200
    },
    {
      "epoch": 1.4487059246103806,
      "grad_norm": 1.5129550695419312,
      "learning_rate": 2.586539484887186e-05,
      "loss": 0.8828,
      "step": 36300
    },
    {
      "epoch": 1.452696904994712,
      "grad_norm": 2.1580302715301514,
      "learning_rate": 2.579887718177948e-05,
      "loss": 0.907,
      "step": 36400
    },
    {
      "epoch": 1.4566878853790435,
      "grad_norm": 2.2810513973236084,
      "learning_rate": 2.5733024691358027e-05,
      "loss": 0.8529,
      "step": 36500
    },
    {
      "epoch": 1.4566878853790435,
      "eval_loss": 0.8217012882232666,
      "eval_runtime": 397.893,
      "eval_samples_per_second": 15.743,
      "eval_steps_per_second": 15.743,
      "step": 36500
    },
    {
      "epoch": 1.460678865763375,
      "grad_norm": 2.4594669342041016,
      "learning_rate": 2.5666507024265646e-05,
      "loss": 0.8481,
      "step": 36600
    },
    {
      "epoch": 1.4646698461477061,
      "grad_norm": 2.2286593914031982,
      "learning_rate": 2.5599989357173264e-05,
      "loss": 0.8142,
      "step": 36700
    },
    {
      "epoch": 1.4686608265320376,
      "grad_norm": 3.0353453159332275,
      "learning_rate": 2.5533471690080886e-05,
      "loss": 0.8444,
      "step": 36800
    },
    {
      "epoch": 1.472651806916369,
      "grad_norm": 2.3795406818389893,
      "learning_rate": 2.546695402298851e-05,
      "loss": 0.8572,
      "step": 36900
    },
    {
      "epoch": 1.4766427873007004,
      "grad_norm": 3.058837890625,
      "learning_rate": 2.540043635589613e-05,
      "loss": 0.8653,
      "step": 37000
    },
    {
      "epoch": 1.4766427873007004,
      "eval_loss": 0.8205384016036987,
      "eval_runtime": 407.2974,
      "eval_samples_per_second": 15.379,
      "eval_steps_per_second": 15.379,
      "step": 37000
    },
    {
      "epoch": 1.4806337676850319,
      "grad_norm": 2.7706172466278076,
      "learning_rate": 2.5333918688803748e-05,
      "loss": 0.8285,
      "step": 37100
    },
    {
      "epoch": 1.4846247480693633,
      "grad_norm": 2.804227590560913,
      "learning_rate": 2.5267401021711366e-05,
      "loss": 0.8506,
      "step": 37200
    },
    {
      "epoch": 1.4886157284536947,
      "grad_norm": 3.205099582672119,
      "learning_rate": 2.5200883354618988e-05,
      "loss": 0.8052,
      "step": 37300
    },
    {
      "epoch": 1.492606708838026,
      "grad_norm": 3.050201416015625,
      "learning_rate": 2.5134365687526606e-05,
      "loss": 0.8548,
      "step": 37400
    },
    {
      "epoch": 1.4965976892223574,
      "grad_norm": 1.9363689422607422,
      "learning_rate": 2.5068513197105154e-05,
      "loss": 0.8625,
      "step": 37500
    },
    {
      "epoch": 1.4965976892223574,
      "eval_loss": 0.822494626045227,
      "eval_runtime": 399.6354,
      "eval_samples_per_second": 15.674,
      "eval_steps_per_second": 15.674,
      "step": 37500
    },
    {
      "epoch": 1.5005886696066888,
      "grad_norm": 0.7678421139717102,
      "learning_rate": 2.5001995530012773e-05,
      "loss": 0.857,
      "step": 37600
    },
    {
      "epoch": 1.5045796499910202,
      "grad_norm": 2.4251344203948975,
      "learning_rate": 2.493547786292039e-05,
      "loss": 0.7993,
      "step": 37700
    },
    {
      "epoch": 1.5085706303753517,
      "grad_norm": 5.314904689788818,
      "learning_rate": 2.4868960195828013e-05,
      "loss": 0.8229,
      "step": 37800
    },
    {
      "epoch": 1.512561610759683,
      "grad_norm": 2.7776055335998535,
      "learning_rate": 2.4802442528735635e-05,
      "loss": 0.804,
      "step": 37900
    },
    {
      "epoch": 1.5165525911440145,
      "grad_norm": 0.9894104599952698,
      "learning_rate": 2.4735924861643253e-05,
      "loss": 0.8524,
      "step": 38000
    },
    {
      "epoch": 1.5165525911440145,
      "eval_loss": 0.8212896585464478,
      "eval_runtime": 400.4034,
      "eval_samples_per_second": 15.644,
      "eval_steps_per_second": 15.644,
      "step": 38000
    },
    {
      "epoch": 1.520543571528346,
      "grad_norm": 2.396695375442505,
      "learning_rate": 2.466940719455087e-05,
      "loss": 0.8377,
      "step": 38100
    },
    {
      "epoch": 1.5245345519126774,
      "grad_norm": 3.1152424812316895,
      "learning_rate": 2.4602889527458493e-05,
      "loss": 0.8645,
      "step": 38200
    },
    {
      "epoch": 1.5285255322970088,
      "grad_norm": 2.926147937774658,
      "learning_rate": 2.4536371860366115e-05,
      "loss": 0.8686,
      "step": 38300
    },
    {
      "epoch": 1.5325165126813403,
      "grad_norm": 2.5936503410339355,
      "learning_rate": 2.4469854193273733e-05,
      "loss": 0.8458,
      "step": 38400
    },
    {
      "epoch": 1.5365074930656717,
      "grad_norm": 1.8961191177368164,
      "learning_rate": 2.4403336526181355e-05,
      "loss": 0.8212,
      "step": 38500
    },
    {
      "epoch": 1.5365074930656717,
      "eval_loss": 0.8220006227493286,
      "eval_runtime": 406.798,
      "eval_samples_per_second": 15.398,
      "eval_steps_per_second": 15.398,
      "step": 38500
    },
    {
      "epoch": 1.5404984734500031,
      "grad_norm": 2.694892168045044,
      "learning_rate": 2.4336818859088974e-05,
      "loss": 0.8507,
      "step": 38600
    },
    {
      "epoch": 1.5444894538343346,
      "grad_norm": 2.9239418506622314,
      "learning_rate": 2.4270301191996595e-05,
      "loss": 0.854,
      "step": 38700
    },
    {
      "epoch": 1.5484804342186658,
      "grad_norm": 2.639812469482422,
      "learning_rate": 2.4203783524904217e-05,
      "loss": 0.8405,
      "step": 38800
    },
    {
      "epoch": 1.5524714146029972,
      "grad_norm": 1.7877484560012817,
      "learning_rate": 2.4137265857811836e-05,
      "loss": 0.8551,
      "step": 38900
    },
    {
      "epoch": 1.5564623949873286,
      "grad_norm": 2.7478761672973633,
      "learning_rate": 2.4070748190719454e-05,
      "loss": 0.8382,
      "step": 39000
    },
    {
      "epoch": 1.5564623949873286,
      "eval_loss": 0.8198854923248291,
      "eval_runtime": 410.7221,
      "eval_samples_per_second": 15.251,
      "eval_steps_per_second": 15.251,
      "step": 39000
    },
    {
      "epoch": 1.56045337537166,
      "grad_norm": 1.2712368965148926,
      "learning_rate": 2.400423052362708e-05,
      "loss": 0.8499,
      "step": 39100
    },
    {
      "epoch": 1.5644443557559915,
      "grad_norm": 2.6375234127044678,
      "learning_rate": 2.3937712856534698e-05,
      "loss": 0.899,
      "step": 39200
    },
    {
      "epoch": 1.5684353361403227,
      "grad_norm": 2.934464931488037,
      "learning_rate": 2.3871195189442316e-05,
      "loss": 0.8306,
      "step": 39300
    },
    {
      "epoch": 1.5724263165246541,
      "grad_norm": 2.4473860263824463,
      "learning_rate": 2.3804677522349938e-05,
      "loss": 0.8604,
      "step": 39400
    },
    {
      "epoch": 1.5764172969089856,
      "grad_norm": 1.8816015720367432,
      "learning_rate": 2.373815985525756e-05,
      "loss": 0.8617,
      "step": 39500
    },
    {
      "epoch": 1.5764172969089856,
      "eval_loss": 0.8190008997917175,
      "eval_runtime": 419.7325,
      "eval_samples_per_second": 14.924,
      "eval_steps_per_second": 14.924,
      "step": 39500
    },
    {
      "epoch": 1.580408277293317,
      "grad_norm": 3.070603132247925,
      "learning_rate": 2.3671642188165178e-05,
      "loss": 0.8635,
      "step": 39600
    },
    {
      "epoch": 1.5843992576776484,
      "grad_norm": 2.654827833175659,
      "learning_rate": 2.3605124521072796e-05,
      "loss": 0.823,
      "step": 39700
    },
    {
      "epoch": 1.5883902380619799,
      "grad_norm": 2.918883800506592,
      "learning_rate": 2.3538606853980418e-05,
      "loss": 0.8258,
      "step": 39800
    },
    {
      "epoch": 1.5923812184463113,
      "grad_norm": 2.233581781387329,
      "learning_rate": 2.3472089186888037e-05,
      "loss": 0.8917,
      "step": 39900
    },
    {
      "epoch": 1.5963721988306427,
      "grad_norm": 2.769590139389038,
      "learning_rate": 2.340557151979566e-05,
      "loss": 0.8852,
      "step": 40000
    },
    {
      "epoch": 1.5963721988306427,
      "eval_loss": 0.8156577944755554,
      "eval_runtime": 593.9769,
      "eval_samples_per_second": 10.546,
      "eval_steps_per_second": 10.546,
      "step": 40000
    },
    {
      "epoch": 1.6003631792149742,
      "grad_norm": 2.740922689437866,
      "learning_rate": 2.333905385270328e-05,
      "loss": 0.8283,
      "step": 40100
    },
    {
      "epoch": 1.6043541595993056,
      "grad_norm": 6.717237949371338,
      "learning_rate": 2.32725361856109e-05,
      "loss": 0.8712,
      "step": 40200
    },
    {
      "epoch": 1.608345139983637,
      "grad_norm": 2.721628189086914,
      "learning_rate": 2.3206018518518517e-05,
      "loss": 0.8257,
      "step": 40300
    },
    {
      "epoch": 1.6123361203679685,
      "grad_norm": 2.0241870880126953,
      "learning_rate": 2.3139500851426142e-05,
      "loss": 0.8403,
      "step": 40400
    },
    {
      "epoch": 1.6163271007523,
      "grad_norm": 1.4820959568023682,
      "learning_rate": 2.307298318433376e-05,
      "loss": 0.8828,
      "step": 40500
    },
    {
      "epoch": 1.6163271007523,
      "eval_loss": 0.8125161528587341,
      "eval_runtime": 531.876,
      "eval_samples_per_second": 11.777,
      "eval_steps_per_second": 11.777,
      "step": 40500
    },
    {
      "epoch": 1.6203180811366313,
      "grad_norm": 2.8091607093811035,
      "learning_rate": 2.300646551724138e-05,
      "loss": 0.8586,
      "step": 40600
    },
    {
      "epoch": 1.6243090615209628,
      "grad_norm": 3.149022340774536,
      "learning_rate": 2.2939947850149e-05,
      "loss": 0.8781,
      "step": 40700
    },
    {
      "epoch": 1.628300041905294,
      "grad_norm": 2.527614116668701,
      "learning_rate": 2.2873430183056623e-05,
      "loss": 0.8466,
      "step": 40800
    },
    {
      "epoch": 1.6322910222896254,
      "grad_norm": 2.4786550998687744,
      "learning_rate": 2.280691251596424e-05,
      "loss": 0.8353,
      "step": 40900
    },
    {
      "epoch": 1.6362820026739568,
      "grad_norm": 2.782644033432007,
      "learning_rate": 2.2740394848871863e-05,
      "loss": 0.8382,
      "step": 41000
    },
    {
      "epoch": 1.6362820026739568,
      "eval_loss": 0.8157525658607483,
      "eval_runtime": 502.792,
      "eval_samples_per_second": 12.458,
      "eval_steps_per_second": 12.458,
      "step": 41000
    },
    {
      "epoch": 1.6402729830582883,
      "grad_norm": 2.7742199897766113,
      "learning_rate": 2.267387718177948e-05,
      "loss": 0.8584,
      "step": 41100
    },
    {
      "epoch": 1.6442639634426197,
      "grad_norm": 2.5590806007385254,
      "learning_rate": 2.2607359514687103e-05,
      "loss": 0.8733,
      "step": 41200
    },
    {
      "epoch": 1.648254943826951,
      "grad_norm": 2.096721887588501,
      "learning_rate": 2.2540841847594725e-05,
      "loss": 0.8344,
      "step": 41300
    },
    {
      "epoch": 1.6522459242112824,
      "grad_norm": 3.186685800552368,
      "learning_rate": 2.2474324180502343e-05,
      "loss": 0.8594,
      "step": 41400
    },
    {
      "epoch": 1.6562369045956138,
      "grad_norm": 2.1136012077331543,
      "learning_rate": 2.2408471690080888e-05,
      "loss": 0.8399,
      "step": 41500
    },
    {
      "epoch": 1.6562369045956138,
      "eval_loss": 0.811316192150116,
      "eval_runtime": 745.0295,
      "eval_samples_per_second": 8.408,
      "eval_steps_per_second": 8.408,
      "step": 41500
    },
    {
      "epoch": 1.6602278849799452,
      "grad_norm": 2.530672073364258,
      "learning_rate": 2.2341954022988506e-05,
      "loss": 0.8371,
      "step": 41600
    },
    {
      "epoch": 1.6642188653642767,
      "grad_norm": 3.35518741607666,
      "learning_rate": 2.2275436355896124e-05,
      "loss": 0.8528,
      "step": 41700
    },
    {
      "epoch": 1.668209845748608,
      "grad_norm": 2.327655076980591,
      "learning_rate": 2.220891868880375e-05,
      "loss": 0.8657,
      "step": 41800
    },
    {
      "epoch": 1.6722008261329395,
      "grad_norm": 0.6857519149780273,
      "learning_rate": 2.2142401021711368e-05,
      "loss": 0.8414,
      "step": 41900
    },
    {
      "epoch": 1.676191806517271,
      "grad_norm": 2.8705101013183594,
      "learning_rate": 2.2075883354618986e-05,
      "loss": 0.8411,
      "step": 42000
    },
    {
      "epoch": 1.676191806517271,
      "eval_loss": 0.809863269329071,
      "eval_runtime": 539.2763,
      "eval_samples_per_second": 11.616,
      "eval_steps_per_second": 11.616,
      "step": 42000
    },
    {
      "epoch": 1.6801827869016024,
      "grad_norm": 1.9529361724853516,
      "learning_rate": 2.2009365687526608e-05,
      "loss": 0.8217,
      "step": 42100
    },
    {
      "epoch": 1.6841737672859338,
      "grad_norm": 2.052119255065918,
      "learning_rate": 2.194284802043423e-05,
      "loss": 0.8186,
      "step": 42200
    },
    {
      "epoch": 1.6881647476702653,
      "grad_norm": 1.55492103099823,
      "learning_rate": 2.187633035334185e-05,
      "loss": 0.805,
      "step": 42300
    },
    {
      "epoch": 1.6921557280545967,
      "grad_norm": 2.904863119125366,
      "learning_rate": 2.180981268624947e-05,
      "loss": 0.8328,
      "step": 42400
    },
    {
      "epoch": 1.6961467084389281,
      "grad_norm": 2.788588047027588,
      "learning_rate": 2.174329501915709e-05,
      "loss": 0.8748,
      "step": 42500
    },
    {
      "epoch": 1.6961467084389281,
      "eval_loss": 0.808181643486023,
      "eval_runtime": 452.6349,
      "eval_samples_per_second": 13.839,
      "eval_steps_per_second": 13.839,
      "step": 42500
    },
    {
      "epoch": 1.7001376888232596,
      "grad_norm": 0.6122294664382935,
      "learning_rate": 2.1677442528735633e-05,
      "loss": 0.8449,
      "step": 42600
    },
    {
      "epoch": 1.704128669207591,
      "grad_norm": 2.7509236335754395,
      "learning_rate": 2.161092486164325e-05,
      "loss": 0.8299,
      "step": 42700
    },
    {
      "epoch": 1.7081196495919224,
      "grad_norm": 2.6101698875427246,
      "learning_rate": 2.1544407194550873e-05,
      "loss": 0.8672,
      "step": 42800
    },
    {
      "epoch": 1.7121106299762536,
      "grad_norm": 2.47489070892334,
      "learning_rate": 2.1477889527458495e-05,
      "loss": 0.8608,
      "step": 42900
    },
    {
      "epoch": 1.716101610360585,
      "grad_norm": 2.624781608581543,
      "learning_rate": 2.1411371860366114e-05,
      "loss": 0.8901,
      "step": 43000
    },
    {
      "epoch": 1.716101610360585,
      "eval_loss": 0.8089461922645569,
      "eval_runtime": 472.214,
      "eval_samples_per_second": 13.265,
      "eval_steps_per_second": 13.265,
      "step": 43000
    },
    {
      "epoch": 1.7200925907449165,
      "grad_norm": 2.6844305992126465,
      "learning_rate": 2.1344854193273732e-05,
      "loss": 0.8535,
      "step": 43100
    },
    {
      "epoch": 1.724083571129248,
      "grad_norm": 3.009474039077759,
      "learning_rate": 2.1278336526181357e-05,
      "loss": 0.8483,
      "step": 43200
    },
    {
      "epoch": 1.7280745515135794,
      "grad_norm": 2.868285655975342,
      "learning_rate": 2.1211818859088976e-05,
      "loss": 0.8375,
      "step": 43300
    },
    {
      "epoch": 1.7320655318979106,
      "grad_norm": 3.09023118019104,
      "learning_rate": 2.1145301191996594e-05,
      "loss": 0.837,
      "step": 43400
    },
    {
      "epoch": 1.736056512282242,
      "grad_norm": 1.6200309991836548,
      "learning_rate": 2.1078783524904216e-05,
      "loss": 0.8404,
      "step": 43500
    },
    {
      "epoch": 1.736056512282242,
      "eval_loss": 0.809330403804779,
      "eval_runtime": 507.6101,
      "eval_samples_per_second": 12.34,
      "eval_steps_per_second": 12.34,
      "step": 43500
    },
    {
      "epoch": 1.7400474926665734,
      "grad_norm": 2.7294631004333496,
      "learning_rate": 2.1012265857811838e-05,
      "loss": 0.8202,
      "step": 43600
    },
    {
      "epoch": 1.7440384730509049,
      "grad_norm": 2.7527127265930176,
      "learning_rate": 2.0945748190719456e-05,
      "loss": 0.8074,
      "step": 43700
    },
    {
      "epoch": 1.7480294534352363,
      "grad_norm": 2.3838725090026855,
      "learning_rate": 2.0879230523627078e-05,
      "loss": 0.8464,
      "step": 43800
    },
    {
      "epoch": 1.7520204338195677,
      "grad_norm": 1.8720425367355347,
      "learning_rate": 2.0812712856534696e-05,
      "loss": 0.8567,
      "step": 43900
    },
    {
      "epoch": 1.7560114142038992,
      "grad_norm": 2.9357850551605225,
      "learning_rate": 2.0746195189442315e-05,
      "loss": 0.8327,
      "step": 44000
    },
    {
      "epoch": 1.7560114142038992,
      "eval_loss": 0.8074397444725037,
      "eval_runtime": 511.2836,
      "eval_samples_per_second": 12.252,
      "eval_steps_per_second": 12.252,
      "step": 44000
    },
    {
      "epoch": 1.7600023945882306,
      "grad_norm": 2.3352153301239014,
      "learning_rate": 2.067967752234994e-05,
      "loss": 0.8217,
      "step": 44100
    },
    {
      "epoch": 1.763993374972562,
      "grad_norm": 1.2209688425064087,
      "learning_rate": 2.0613159855257558e-05,
      "loss": 0.8238,
      "step": 44200
    },
    {
      "epoch": 1.7679843553568935,
      "grad_norm": 2.192108392715454,
      "learning_rate": 2.0546642188165177e-05,
      "loss": 0.8487,
      "step": 44300
    },
    {
      "epoch": 1.771975335741225,
      "grad_norm": 2.811412811279297,
      "learning_rate": 2.0480124521072795e-05,
      "loss": 0.8084,
      "step": 44400
    },
    {
      "epoch": 1.7759663161255563,
      "grad_norm": 1.2231508493423462,
      "learning_rate": 2.041360685398042e-05,
      "loss": 0.7903,
      "step": 44500
    },
    {
      "epoch": 1.7759663161255563,
      "eval_loss": 0.8063774108886719,
      "eval_runtime": 642.0095,
      "eval_samples_per_second": 9.757,
      "eval_steps_per_second": 9.757,
      "step": 44500
    },
    {
      "epoch": 1.7799572965098878,
      "grad_norm": 2.7958383560180664,
      "learning_rate": 2.034708918688804e-05,
      "loss": 0.8348,
      "step": 44600
    },
    {
      "epoch": 1.7839482768942192,
      "grad_norm": 1.86952543258667,
      "learning_rate": 2.0280571519795657e-05,
      "loss": 0.8722,
      "step": 44700
    },
    {
      "epoch": 1.7879392572785506,
      "grad_norm": 1.9730616807937622,
      "learning_rate": 2.021405385270328e-05,
      "loss": 0.8369,
      "step": 44800
    },
    {
      "epoch": 1.7919302376628818,
      "grad_norm": 3.2306602001190186,
      "learning_rate": 2.01475361856109e-05,
      "loss": 0.8431,
      "step": 44900
    },
    {
      "epoch": 1.7959212180472133,
      "grad_norm": 2.288360118865967,
      "learning_rate": 2.008101851851852e-05,
      "loss": 0.8531,
      "step": 45000
    },
    {
      "epoch": 1.7959212180472133,
      "eval_loss": 0.8057777285575867,
      "eval_runtime": 627.0561,
      "eval_samples_per_second": 9.99,
      "eval_steps_per_second": 9.99,
      "step": 45000
    },
    {
      "epoch": 1.7999121984315447,
      "grad_norm": 2.171807289123535,
      "learning_rate": 2.001450085142614e-05,
      "loss": 0.8516,
      "step": 45100
    },
    {
      "epoch": 1.8039031788158761,
      "grad_norm": 2.011547327041626,
      "learning_rate": 1.994798318433376e-05,
      "loss": 0.868,
      "step": 45200
    },
    {
      "epoch": 1.8078941592002076,
      "grad_norm": 2.877462148666382,
      "learning_rate": 1.988146551724138e-05,
      "loss": 0.832,
      "step": 45300
    },
    {
      "epoch": 1.8118851395845388,
      "grad_norm": 2.2609381675720215,
      "learning_rate": 1.9814947850149003e-05,
      "loss": 0.8727,
      "step": 45400
    },
    {
      "epoch": 1.8158761199688702,
      "grad_norm": 2.540832757949829,
      "learning_rate": 1.974843018305662e-05,
      "loss": 0.8235,
      "step": 45500
    },
    {
      "epoch": 1.8158761199688702,
      "eval_loss": 0.8040196895599365,
      "eval_runtime": 322.132,
      "eval_samples_per_second": 19.445,
      "eval_steps_per_second": 19.445,
      "step": 45500
    },
    {
      "epoch": 1.8198671003532016,
      "grad_norm": 1.9358195066452026,
      "learning_rate": 1.968191251596424e-05,
      "loss": 0.8443,
      "step": 45600
    },
    {
      "epoch": 1.823858080737533,
      "grad_norm": 2.841702461242676,
      "learning_rate": 1.961539484887186e-05,
      "loss": 0.84,
      "step": 45700
    },
    {
      "epoch": 1.8278490611218645,
      "grad_norm": 2.3490681648254395,
      "learning_rate": 1.9548877181779483e-05,
      "loss": 0.7693,
      "step": 45800
    },
    {
      "epoch": 1.831840041506196,
      "grad_norm": 2.176862955093384,
      "learning_rate": 1.94823595146871e-05,
      "loss": 0.8646,
      "step": 45900
    },
    {
      "epoch": 1.8358310218905274,
      "grad_norm": 1.0297925472259521,
      "learning_rate": 1.9415841847594723e-05,
      "loss": 0.8457,
      "step": 46000
    },
    {
      "epoch": 1.8358310218905274,
      "eval_loss": 0.8040635585784912,
      "eval_runtime": 317.7798,
      "eval_samples_per_second": 19.712,
      "eval_steps_per_second": 19.712,
      "step": 46000
    },
    {
      "epoch": 1.8398220022748588,
      "grad_norm": 2.119067430496216,
      "learning_rate": 1.9349324180502342e-05,
      "loss": 0.8268,
      "step": 46100
    },
    {
      "epoch": 1.8438129826591902,
      "grad_norm": 2.3519859313964844,
      "learning_rate": 1.9282806513409964e-05,
      "loss": 0.8501,
      "step": 46200
    },
    {
      "epoch": 1.8478039630435217,
      "grad_norm": 2.7394843101501465,
      "learning_rate": 1.9216288846317582e-05,
      "loss": 0.8428,
      "step": 46300
    },
    {
      "epoch": 1.8517949434278531,
      "grad_norm": 1.875815510749817,
      "learning_rate": 1.9149771179225204e-05,
      "loss": 0.8306,
      "step": 46400
    },
    {
      "epoch": 1.8557859238121845,
      "grad_norm": 2.6806552410125732,
      "learning_rate": 1.9083253512132822e-05,
      "loss": 0.8251,
      "step": 46500
    },
    {
      "epoch": 1.8557859238121845,
      "eval_loss": 0.8031918406486511,
      "eval_runtime": 314.5395,
      "eval_samples_per_second": 19.915,
      "eval_steps_per_second": 19.915,
      "step": 46500
    },
    {
      "epoch": 1.859776904196516,
      "grad_norm": 2.263725519180298,
      "learning_rate": 1.9016735845040444e-05,
      "loss": 0.8421,
      "step": 46600
    },
    {
      "epoch": 1.8637678845808474,
      "grad_norm": 2.429499626159668,
      "learning_rate": 1.895088335461899e-05,
      "loss": 0.8053,
      "step": 46700
    },
    {
      "epoch": 1.8677588649651788,
      "grad_norm": 3.142163038253784,
      "learning_rate": 1.888436568752661e-05,
      "loss": 0.8589,
      "step": 46800
    },
    {
      "epoch": 1.87174984534951,
      "grad_norm": 2.6490607261657715,
      "learning_rate": 1.881784802043423e-05,
      "loss": 0.8276,
      "step": 46900
    },
    {
      "epoch": 1.8757408257338415,
      "grad_norm": 2.4873907566070557,
      "learning_rate": 1.8751330353341847e-05,
      "loss": 0.8448,
      "step": 47000
    },
    {
      "epoch": 1.8757408257338415,
      "eval_loss": 0.8028134107589722,
      "eval_runtime": 317.7594,
      "eval_samples_per_second": 19.713,
      "eval_steps_per_second": 19.713,
      "step": 47000
    },
    {
      "epoch": 1.879731806118173,
      "grad_norm": 2.565678358078003,
      "learning_rate": 1.868481268624947e-05,
      "loss": 0.8123,
      "step": 47100
    },
    {
      "epoch": 1.8837227865025044,
      "grad_norm": 2.975177526473999,
      "learning_rate": 1.861829501915709e-05,
      "loss": 0.8188,
      "step": 47200
    },
    {
      "epoch": 1.8877137668868358,
      "grad_norm": 1.9207770824432373,
      "learning_rate": 1.855177735206471e-05,
      "loss": 0.7996,
      "step": 47300
    },
    {
      "epoch": 1.891704747271167,
      "grad_norm": 2.9899890422821045,
      "learning_rate": 1.848525968497233e-05,
      "loss": 0.8578,
      "step": 47400
    },
    {
      "epoch": 1.8956957276554984,
      "grad_norm": 3.2630558013916016,
      "learning_rate": 1.841874201787995e-05,
      "loss": 0.8072,
      "step": 47500
    },
    {
      "epoch": 1.8956957276554984,
      "eval_loss": 0.8023215532302856,
      "eval_runtime": 319.0213,
      "eval_samples_per_second": 19.635,
      "eval_steps_per_second": 19.635,
      "step": 47500
    },
    {
      "epoch": 1.8996867080398299,
      "grad_norm": 2.639286518096924,
      "learning_rate": 1.835222435078757e-05,
      "loss": 0.768,
      "step": 47600
    },
    {
      "epoch": 1.9036776884241613,
      "grad_norm": 2.403061866760254,
      "learning_rate": 1.828570668369519e-05,
      "loss": 0.8168,
      "step": 47700
    },
    {
      "epoch": 1.9076686688084927,
      "grad_norm": 2.705721378326416,
      "learning_rate": 1.821918901660281e-05,
      "loss": 0.8175,
      "step": 47800
    },
    {
      "epoch": 1.9116596491928242,
      "grad_norm": 2.04512357711792,
      "learning_rate": 1.815267134951043e-05,
      "loss": 0.8457,
      "step": 47900
    },
    {
      "epoch": 1.9156506295771556,
      "grad_norm": 2.4074347019195557,
      "learning_rate": 1.808615368241805e-05,
      "loss": 0.8382,
      "step": 48000
    },
    {
      "epoch": 1.9156506295771556,
      "eval_loss": 0.8012018799781799,
      "eval_runtime": 315.7852,
      "eval_samples_per_second": 19.836,
      "eval_steps_per_second": 19.836,
      "step": 48000
    },
    {
      "epoch": 1.919641609961487,
      "grad_norm": 2.776797294616699,
      "learning_rate": 1.8019636015325673e-05,
      "loss": 0.8516,
      "step": 48100
    },
    {
      "epoch": 1.9236325903458185,
      "grad_norm": 2.5124120712280273,
      "learning_rate": 1.795311834823329e-05,
      "loss": 0.8087,
      "step": 48200
    },
    {
      "epoch": 1.92762357073015,
      "grad_norm": 2.725811719894409,
      "learning_rate": 1.788660068114091e-05,
      "loss": 0.8275,
      "step": 48300
    },
    {
      "epoch": 1.9316145511144813,
      "grad_norm": 2.3710694313049316,
      "learning_rate": 1.7820748190719455e-05,
      "loss": 0.8521,
      "step": 48400
    },
    {
      "epoch": 1.9356055314988128,
      "grad_norm": 2.7496511936187744,
      "learning_rate": 1.7754230523627076e-05,
      "loss": 0.8244,
      "step": 48500
    },
    {
      "epoch": 1.9356055314988128,
      "eval_loss": 0.7991548180580139,
      "eval_runtime": 314.7801,
      "eval_samples_per_second": 19.9,
      "eval_steps_per_second": 19.9,
      "step": 48500
    },
    {
      "epoch": 1.9395965118831442,
      "grad_norm": 2.7006888389587402,
      "learning_rate": 1.7687712856534698e-05,
      "loss": 0.7883,
      "step": 48600
    },
    {
      "epoch": 1.9435874922674756,
      "grad_norm": 2.276465892791748,
      "learning_rate": 1.7621195189442317e-05,
      "loss": 0.8975,
      "step": 48700
    },
    {
      "epoch": 1.947578472651807,
      "grad_norm": 2.6475777626037598,
      "learning_rate": 1.755467752234994e-05,
      "loss": 0.8199,
      "step": 48800
    },
    {
      "epoch": 1.9515694530361385,
      "grad_norm": 2.815408706665039,
      "learning_rate": 1.7488159855257557e-05,
      "loss": 0.8519,
      "step": 48900
    },
    {
      "epoch": 1.9555604334204697,
      "grad_norm": 2.625026226043701,
      "learning_rate": 1.742164218816518e-05,
      "loss": 0.8331,
      "step": 49000
    },
    {
      "epoch": 1.9555604334204697,
      "eval_loss": 0.8002820014953613,
      "eval_runtime": 313.1479,
      "eval_samples_per_second": 20.003,
      "eval_steps_per_second": 20.003,
      "step": 49000
    },
    {
      "epoch": 1.9595514138048011,
      "grad_norm": 1.914518117904663,
      "learning_rate": 1.7355124521072797e-05,
      "loss": 0.8152,
      "step": 49100
    },
    {
      "epoch": 1.9635423941891326,
      "grad_norm": 2.4312174320220947,
      "learning_rate": 1.728860685398042e-05,
      "loss": 0.8588,
      "step": 49200
    },
    {
      "epoch": 1.967533374573464,
      "grad_norm": 2.537097454071045,
      "learning_rate": 1.7222089186888037e-05,
      "loss": 0.7744,
      "step": 49300
    },
    {
      "epoch": 1.9715243549577954,
      "grad_norm": 2.643700361251831,
      "learning_rate": 1.715557151979566e-05,
      "loss": 0.8134,
      "step": 49400
    },
    {
      "epoch": 1.9755153353421266,
      "grad_norm": 2.718132972717285,
      "learning_rate": 1.708905385270328e-05,
      "loss": 0.809,
      "step": 49500
    },
    {
      "epoch": 1.9755153353421266,
      "eval_loss": 0.798513650894165,
      "eval_runtime": 311.3579,
      "eval_samples_per_second": 20.118,
      "eval_steps_per_second": 20.118,
      "step": 49500
    },
    {
      "epoch": 1.979506315726458,
      "grad_norm": 2.9059503078460693,
      "learning_rate": 1.70225361856109e-05,
      "loss": 0.841,
      "step": 49600
    },
    {
      "epoch": 1.9834972961107895,
      "grad_norm": 2.247438430786133,
      "learning_rate": 1.6956018518518518e-05,
      "loss": 0.8333,
      "step": 49700
    },
    {
      "epoch": 1.987488276495121,
      "grad_norm": 3.183072090148926,
      "learning_rate": 1.688950085142614e-05,
      "loss": 0.8435,
      "step": 49800
    },
    {
      "epoch": 1.9914792568794524,
      "grad_norm": 1.8385668992996216,
      "learning_rate": 1.682298318433376e-05,
      "loss": 0.8065,
      "step": 49900
    },
    {
      "epoch": 1.9954702372637838,
      "grad_norm": 3.0071990489959717,
      "learning_rate": 1.675646551724138e-05,
      "loss": 0.8152,
      "step": 50000
    },
    {
      "epoch": 1.9954702372637838,
      "eval_loss": 0.7971177101135254,
      "eval_runtime": 310.7301,
      "eval_samples_per_second": 20.159,
      "eval_steps_per_second": 20.159,
      "step": 50000
    },
    {
      "epoch": 1.9994612176481152,
      "grad_norm": 2.524010419845581,
      "learning_rate": 1.6689947850149e-05,
      "loss": 0.8433,
      "step": 50100
    },
    {
      "epoch": 2.003432243130525,
      "grad_norm": 1.8180935382843018,
      "learning_rate": 1.662343018305662e-05,
      "loss": 0.7974,
      "step": 50200
    },
    {
      "epoch": 2.0074232235148566,
      "grad_norm": 2.5707767009735107,
      "learning_rate": 1.655691251596424e-05,
      "loss": 0.7993,
      "step": 50300
    },
    {
      "epoch": 2.011414203899188,
      "grad_norm": 2.832767963409424,
      "learning_rate": 1.6490394848871863e-05,
      "loss": 0.8299,
      "step": 50400
    },
    {
      "epoch": 2.0154051842835194,
      "grad_norm": 2.607480049133301,
      "learning_rate": 1.6423877181779482e-05,
      "loss": 0.8485,
      "step": 50500
    },
    {
      "epoch": 2.0154051842835194,
      "eval_loss": 0.7989190220832825,
      "eval_runtime": 312.3392,
      "eval_samples_per_second": 20.055,
      "eval_steps_per_second": 20.055,
      "step": 50500
    },
    {
      "epoch": 2.0193961646678504,
      "grad_norm": 2.2377092838287354,
      "learning_rate": 1.63573595146871e-05,
      "loss": 0.7917,
      "step": 50600
    },
    {
      "epoch": 2.023387145052182,
      "grad_norm": Infinity,
      "learning_rate": 1.6290841847594722e-05,
      "loss": 0.8131,
      "step": 50700
    },
    {
      "epoch": 2.0273781254365133,
      "grad_norm": 2.0873522758483887,
      "learning_rate": 1.6224989357173263e-05,
      "loss": 0.8477,
      "step": 50800
    },
    {
      "epoch": 2.0313691058208447,
      "grad_norm": 2.0942068099975586,
      "learning_rate": 1.6158471690080888e-05,
      "loss": 0.8048,
      "step": 50900
    },
    {
      "epoch": 2.035360086205176,
      "grad_norm": 3.053346872329712,
      "learning_rate": 1.6091954022988507e-05,
      "loss": 0.8049,
      "step": 51000
    },
    {
      "epoch": 2.035360086205176,
      "eval_loss": 0.7967326641082764,
      "eval_runtime": 312.7374,
      "eval_samples_per_second": 20.03,
      "eval_steps_per_second": 20.03,
      "step": 51000
    },
    {
      "epoch": 2.0393510665895076,
      "grad_norm": 0.8784769177436829,
      "learning_rate": 1.6025436355896125e-05,
      "loss": 0.7789,
      "step": 51100
    },
    {
      "epoch": 2.043342046973839,
      "grad_norm": 2.898000955581665,
      "learning_rate": 1.5958918688803747e-05,
      "loss": 0.7951,
      "step": 51200
    },
    {
      "epoch": 2.0473330273581705,
      "grad_norm": 2.4342637062072754,
      "learning_rate": 1.589240102171137e-05,
      "loss": 0.7813,
      "step": 51300
    },
    {
      "epoch": 2.051324007742502,
      "grad_norm": 1.6056536436080933,
      "learning_rate": 1.5825883354618987e-05,
      "loss": 0.8072,
      "step": 51400
    },
    {
      "epoch": 2.0553149881268333,
      "grad_norm": 2.5312130451202393,
      "learning_rate": 1.575936568752661e-05,
      "loss": 0.8355,
      "step": 51500
    },
    {
      "epoch": 2.0553149881268333,
      "eval_loss": 0.796504557132721,
      "eval_runtime": 311.3738,
      "eval_samples_per_second": 20.117,
      "eval_steps_per_second": 20.117,
      "step": 51500
    },
    {
      "epoch": 2.0593059685111648,
      "grad_norm": 2.8754286766052246,
      "learning_rate": 1.5692848020434227e-05,
      "loss": 0.7912,
      "step": 51600
    },
    {
      "epoch": 2.063296948895496,
      "grad_norm": 4.503258228302002,
      "learning_rate": 1.562633035334185e-05,
      "loss": 0.8131,
      "step": 51700
    },
    {
      "epoch": 2.0672879292798276,
      "grad_norm": 2.966113805770874,
      "learning_rate": 1.555981268624947e-05,
      "loss": 0.8137,
      "step": 51800
    },
    {
      "epoch": 2.071278909664159,
      "grad_norm": 2.4777939319610596,
      "learning_rate": 1.549329501915709e-05,
      "loss": 0.8184,
      "step": 51900
    },
    {
      "epoch": 2.0752698900484905,
      "grad_norm": 1.7686082124710083,
      "learning_rate": 1.5426777352064708e-05,
      "loss": 0.8239,
      "step": 52000
    },
    {
      "epoch": 2.0752698900484905,
      "eval_loss": 0.7956023812294006,
      "eval_runtime": 353.0085,
      "eval_samples_per_second": 17.745,
      "eval_steps_per_second": 17.745,
      "step": 52000
    },
    {
      "epoch": 2.079260870432822,
      "grad_norm": 3.353222370147705,
      "learning_rate": 1.536025968497233e-05,
      "loss": 0.8337,
      "step": 52100
    },
    {
      "epoch": 2.0832518508171534,
      "grad_norm": 2.3480567932128906,
      "learning_rate": 1.529374201787995e-05,
      "loss": 0.8091,
      "step": 52200
    },
    {
      "epoch": 2.087242831201485,
      "grad_norm": 2.5945818424224854,
      "learning_rate": 1.522722435078757e-05,
      "loss": 0.7968,
      "step": 52300
    },
    {
      "epoch": 2.0912338115858162,
      "grad_norm": 3.757263660430908,
      "learning_rate": 1.5160706683695188e-05,
      "loss": 0.8199,
      "step": 52400
    },
    {
      "epoch": 2.0952247919701477,
      "grad_norm": 2.9245712757110596,
      "learning_rate": 1.5094189016602812e-05,
      "loss": 0.7933,
      "step": 52500
    },
    {
      "epoch": 2.0952247919701477,
      "eval_loss": 0.7966386675834656,
      "eval_runtime": 395.604,
      "eval_samples_per_second": 15.834,
      "eval_steps_per_second": 15.834,
      "step": 52500
    },
    {
      "epoch": 2.099215772354479,
      "grad_norm": 3.3286314010620117,
      "learning_rate": 1.502767134951043e-05,
      "loss": 0.837,
      "step": 52600
    },
    {
      "epoch": 2.10320675273881,
      "grad_norm": 2.7764837741851807,
      "learning_rate": 1.496115368241805e-05,
      "loss": 0.8118,
      "step": 52700
    },
    {
      "epoch": 2.1071977331231415,
      "grad_norm": 2.0251901149749756,
      "learning_rate": 1.4894636015325672e-05,
      "loss": 0.8518,
      "step": 52800
    },
    {
      "epoch": 2.111188713507473,
      "grad_norm": 1.9479645490646362,
      "learning_rate": 1.4828118348233292e-05,
      "loss": 0.7728,
      "step": 52900
    },
    {
      "epoch": 2.1151796938918044,
      "grad_norm": 2.3124399185180664,
      "learning_rate": 1.476160068114091e-05,
      "loss": 0.8053,
      "step": 53000
    },
    {
      "epoch": 2.1151796938918044,
      "eval_loss": 0.795813262462616,
      "eval_runtime": 401.7293,
      "eval_samples_per_second": 15.593,
      "eval_steps_per_second": 15.593,
      "step": 53000
    },
    {
      "epoch": 2.119170674276136,
      "grad_norm": 1.7631022930145264,
      "learning_rate": 1.4695083014048532e-05,
      "loss": 0.8117,
      "step": 53100
    },
    {
      "epoch": 2.1231616546604672,
      "grad_norm": 2.097378730773926,
      "learning_rate": 1.4628565346956152e-05,
      "loss": 0.8139,
      "step": 53200
    },
    {
      "epoch": 2.1271526350447987,
      "grad_norm": 2.4176087379455566,
      "learning_rate": 1.4562047679863772e-05,
      "loss": 0.7976,
      "step": 53300
    },
    {
      "epoch": 2.13114361542913,
      "grad_norm": 2.76100492477417,
      "learning_rate": 1.4495530012771394e-05,
      "loss": 0.8115,
      "step": 53400
    },
    {
      "epoch": 2.1351345958134615,
      "grad_norm": 2.551340341567993,
      "learning_rate": 1.4429012345679013e-05,
      "loss": 0.7655,
      "step": 53500
    },
    {
      "epoch": 2.1351345958134615,
      "eval_loss": 0.796125054359436,
      "eval_runtime": 408.6052,
      "eval_samples_per_second": 15.33,
      "eval_steps_per_second": 15.33,
      "step": 53500
    },
    {
      "epoch": 2.139125576197793,
      "grad_norm": 3.016995668411255,
      "learning_rate": 1.4362494678586633e-05,
      "loss": 0.8228,
      "step": 53600
    },
    {
      "epoch": 2.1431165565821244,
      "grad_norm": 2.9312658309936523,
      "learning_rate": 1.4295977011494254e-05,
      "loss": 0.8278,
      "step": 53700
    },
    {
      "epoch": 2.147107536966456,
      "grad_norm": 2.6800382137298584,
      "learning_rate": 1.4229459344401875e-05,
      "loss": 0.8056,
      "step": 53800
    },
    {
      "epoch": 2.1510985173507873,
      "grad_norm": 2.751704454421997,
      "learning_rate": 1.4162941677309493e-05,
      "loss": 0.8253,
      "step": 53900
    },
    {
      "epoch": 2.1550894977351187,
      "grad_norm": 3.1024224758148193,
      "learning_rate": 1.4096424010217113e-05,
      "loss": 0.7658,
      "step": 54000
    },
    {
      "epoch": 2.1550894977351187,
      "eval_loss": 0.7944610118865967,
      "eval_runtime": 409.4686,
      "eval_samples_per_second": 15.298,
      "eval_steps_per_second": 15.298,
      "step": 54000
    },
    {
      "epoch": 2.15908047811945,
      "grad_norm": 1.774605631828308,
      "learning_rate": 1.4029906343124735e-05,
      "loss": 0.7433,
      "step": 54100
    },
    {
      "epoch": 2.1630714585037816,
      "grad_norm": 2.276751756668091,
      "learning_rate": 1.3963388676032355e-05,
      "loss": 0.8622,
      "step": 54200
    },
    {
      "epoch": 2.167062438888113,
      "grad_norm": 2.571624755859375,
      "learning_rate": 1.3896871008939973e-05,
      "loss": 0.8266,
      "step": 54300
    },
    {
      "epoch": 2.1710534192724444,
      "grad_norm": 3.5575790405273438,
      "learning_rate": 1.3830353341847597e-05,
      "loss": 0.7701,
      "step": 54400
    },
    {
      "epoch": 2.175044399656776,
      "grad_norm": 2.5961105823516846,
      "learning_rate": 1.3763835674755215e-05,
      "loss": 0.8169,
      "step": 54500
    },
    {
      "epoch": 2.175044399656776,
      "eval_loss": 0.7924103140830994,
      "eval_runtime": 409.1119,
      "eval_samples_per_second": 15.311,
      "eval_steps_per_second": 15.311,
      "step": 54500
    },
    {
      "epoch": 2.1790353800411073,
      "grad_norm": 2.0017058849334717,
      "learning_rate": 1.3697318007662835e-05,
      "loss": 0.844,
      "step": 54600
    },
    {
      "epoch": 2.1830263604254387,
      "grad_norm": 3.201460599899292,
      "learning_rate": 1.3630800340570457e-05,
      "loss": 0.8462,
      "step": 54700
    },
    {
      "epoch": 2.1870173408097697,
      "grad_norm": 1.8391395807266235,
      "learning_rate": 1.3564947850149002e-05,
      "loss": 0.8106,
      "step": 54800
    },
    {
      "epoch": 2.191008321194101,
      "grad_norm": 1.4025382995605469,
      "learning_rate": 1.349843018305662e-05,
      "loss": 0.8027,
      "step": 54900
    },
    {
      "epoch": 2.1949993015784326,
      "grad_norm": 1.962012529373169,
      "learning_rate": 1.343191251596424e-05,
      "loss": 0.7932,
      "step": 55000
    },
    {
      "epoch": 2.1949993015784326,
      "eval_loss": 0.7922912836074829,
      "eval_runtime": 407.3965,
      "eval_samples_per_second": 15.376,
      "eval_steps_per_second": 15.376,
      "step": 55000
    },
    {
      "epoch": 2.198990281962764,
      "grad_norm": 1.0956225395202637,
      "learning_rate": 1.3365394848871862e-05,
      "loss": 0.8164,
      "step": 55100
    },
    {
      "epoch": 2.2029812623470955,
      "grad_norm": 3.9004874229431152,
      "learning_rate": 1.3298877181779482e-05,
      "loss": 0.843,
      "step": 55200
    },
    {
      "epoch": 2.206972242731427,
      "grad_norm": 2.282832622528076,
      "learning_rate": 1.32323595146871e-05,
      "loss": 0.8045,
      "step": 55300
    },
    {
      "epoch": 2.2109632231157583,
      "grad_norm": 2.536952018737793,
      "learning_rate": 1.3165841847594724e-05,
      "loss": 0.8229,
      "step": 55400
    },
    {
      "epoch": 2.2149542035000898,
      "grad_norm": 1.1922978162765503,
      "learning_rate": 1.3099324180502342e-05,
      "loss": 0.8244,
      "step": 55500
    },
    {
      "epoch": 2.2149542035000898,
      "eval_loss": 0.7938923239707947,
      "eval_runtime": 410.879,
      "eval_samples_per_second": 15.245,
      "eval_steps_per_second": 15.245,
      "step": 55500
    },
    {
      "epoch": 2.218945183884421,
      "grad_norm": 1.9967842102050781,
      "learning_rate": 1.3032806513409962e-05,
      "loss": 0.8025,
      "step": 55600
    },
    {
      "epoch": 2.2229361642687526,
      "grad_norm": 2.0683906078338623,
      "learning_rate": 1.2966288846317581e-05,
      "loss": 0.778,
      "step": 55700
    },
    {
      "epoch": 2.226927144653084,
      "grad_norm": 2.505645751953125,
      "learning_rate": 1.2899771179225204e-05,
      "loss": 0.8233,
      "step": 55800
    },
    {
      "epoch": 2.2309181250374155,
      "grad_norm": 2.920926570892334,
      "learning_rate": 1.2833253512132823e-05,
      "loss": 0.7518,
      "step": 55900
    },
    {
      "epoch": 2.234909105421747,
      "grad_norm": 2.714775800704956,
      "learning_rate": 1.2766735845040443e-05,
      "loss": 0.7835,
      "step": 56000
    },
    {
      "epoch": 2.234909105421747,
      "eval_loss": 0.7923334836959839,
      "eval_runtime": 413.3276,
      "eval_samples_per_second": 15.155,
      "eval_steps_per_second": 15.155,
      "step": 56000
    },
    {
      "epoch": 2.2389000858060784,
      "grad_norm": 2.9381673336029053,
      "learning_rate": 1.2700218177948065e-05,
      "loss": 0.7741,
      "step": 56100
    },
    {
      "epoch": 2.24289106619041,
      "grad_norm": 3.0422492027282715,
      "learning_rate": 1.2633700510855683e-05,
      "loss": 0.7795,
      "step": 56200
    },
    {
      "epoch": 2.246882046574741,
      "grad_norm": 2.6515345573425293,
      "learning_rate": 1.2567182843763303e-05,
      "loss": 0.797,
      "step": 56300
    },
    {
      "epoch": 2.2508730269590727,
      "grad_norm": 2.593789577484131,
      "learning_rate": 1.2500665176670925e-05,
      "loss": 0.7832,
      "step": 56400
    },
    {
      "epoch": 2.254864007343404,
      "grad_norm": 2.787356376647949,
      "learning_rate": 1.2434147509578545e-05,
      "loss": 0.8393,
      "step": 56500
    },
    {
      "epoch": 2.254864007343404,
      "eval_loss": 0.7908517718315125,
      "eval_runtime": 416.0239,
      "eval_samples_per_second": 15.057,
      "eval_steps_per_second": 15.057,
      "step": 56500
    },
    {
      "epoch": 2.2588549877277355,
      "grad_norm": 2.539731740951538,
      "learning_rate": 1.2367629842486165e-05,
      "loss": 0.8307,
      "step": 56600
    },
    {
      "epoch": 2.2628459681120665,
      "grad_norm": 1.0901882648468018,
      "learning_rate": 1.2301777352064708e-05,
      "loss": 0.7833,
      "step": 56700
    },
    {
      "epoch": 2.2668369484963984,
      "grad_norm": 2.864835262298584,
      "learning_rate": 1.223525968497233e-05,
      "loss": 0.7782,
      "step": 56800
    },
    {
      "epoch": 2.2708279288807294,
      "grad_norm": 2.3917489051818848,
      "learning_rate": 1.216874201787995e-05,
      "loss": 0.831,
      "step": 56900
    },
    {
      "epoch": 2.274818909265061,
      "grad_norm": 2.2706995010375977,
      "learning_rate": 1.210222435078757e-05,
      "loss": 0.8553,
      "step": 57000
    },
    {
      "epoch": 2.274818909265061,
      "eval_loss": 0.7897313237190247,
      "eval_runtime": 417.2175,
      "eval_samples_per_second": 15.014,
      "eval_steps_per_second": 15.014,
      "step": 57000
    },
    {
      "epoch": 2.2788098896493922,
      "grad_norm": 2.509277582168579,
      "learning_rate": 1.203570668369519e-05,
      "loss": 0.7875,
      "step": 57100
    },
    {
      "epoch": 2.2828008700337237,
      "grad_norm": 1.8876334428787231,
      "learning_rate": 1.196918901660281e-05,
      "loss": 0.8051,
      "step": 57200
    },
    {
      "epoch": 2.286791850418055,
      "grad_norm": 2.2354297637939453,
      "learning_rate": 1.190267134951043e-05,
      "loss": 0.7991,
      "step": 57300
    },
    {
      "epoch": 2.2907828308023865,
      "grad_norm": 2.3196494579315186,
      "learning_rate": 1.183615368241805e-05,
      "loss": 0.8163,
      "step": 57400
    },
    {
      "epoch": 2.294773811186718,
      "grad_norm": 1.9025042057037354,
      "learning_rate": 1.176963601532567e-05,
      "loss": 0.848,
      "step": 57500
    },
    {
      "epoch": 2.294773811186718,
      "eval_loss": 0.7890985012054443,
      "eval_runtime": 418.9263,
      "eval_samples_per_second": 14.953,
      "eval_steps_per_second": 14.953,
      "step": 57500
    },
    {
      "epoch": 2.2987647915710494,
      "grad_norm": 2.7095799446105957,
      "learning_rate": 1.170311834823329e-05,
      "loss": 0.8325,
      "step": 57600
    },
    {
      "epoch": 2.302755771955381,
      "grad_norm": 2.752939224243164,
      "learning_rate": 1.1636600681140912e-05,
      "loss": 0.817,
      "step": 57700
    },
    {
      "epoch": 2.3067467523397123,
      "grad_norm": 2.267987012863159,
      "learning_rate": 1.157008301404853e-05,
      "loss": 0.836,
      "step": 57800
    },
    {
      "epoch": 2.3107377327240437,
      "grad_norm": 1.7722773551940918,
      "learning_rate": 1.1503565346956153e-05,
      "loss": 0.8178,
      "step": 57900
    },
    {
      "epoch": 2.314728713108375,
      "grad_norm": 2.76292085647583,
      "learning_rate": 1.1437047679863773e-05,
      "loss": 0.8185,
      "step": 58000
    },
    {
      "epoch": 2.314728713108375,
      "eval_loss": 0.7884826064109802,
      "eval_runtime": 425.9128,
      "eval_samples_per_second": 14.707,
      "eval_steps_per_second": 14.707,
      "step": 58000
    },
    {
      "epoch": 2.3187196934927066,
      "grad_norm": 2.488321304321289,
      "learning_rate": 1.1370530012771393e-05,
      "loss": 0.7813,
      "step": 58100
    },
    {
      "epoch": 2.322710673877038,
      "grad_norm": 2.6411471366882324,
      "learning_rate": 1.1304012345679013e-05,
      "loss": 0.8157,
      "step": 58200
    },
    {
      "epoch": 2.3267016542613694,
      "grad_norm": 2.29996395111084,
      "learning_rate": 1.1237494678586633e-05,
      "loss": 0.799,
      "step": 58300
    },
    {
      "epoch": 2.330692634645701,
      "grad_norm": 2.8244574069976807,
      "learning_rate": 1.1170977011494253e-05,
      "loss": 0.8052,
      "step": 58400
    },
    {
      "epoch": 2.3346836150300323,
      "grad_norm": 2.609487771987915,
      "learning_rate": 1.1104459344401875e-05,
      "loss": 0.8192,
      "step": 58500
    },
    {
      "epoch": 2.3346836150300323,
      "eval_loss": 0.7897776365280151,
      "eval_runtime": 616.2577,
      "eval_samples_per_second": 10.165,
      "eval_steps_per_second": 10.165,
      "step": 58500
    },
    {
      "epoch": 2.3386745954143633,
      "grad_norm": 0.7581378817558289,
      "learning_rate": 1.1037941677309493e-05,
      "loss": 0.786,
      "step": 58600
    },
    {
      "epoch": 2.342665575798695,
      "grad_norm": 3.016946315765381,
      "learning_rate": 1.0971424010217115e-05,
      "loss": 0.7982,
      "step": 58700
    },
    {
      "epoch": 2.346656556183026,
      "grad_norm": 2.3036270141601562,
      "learning_rate": 1.0904906343124735e-05,
      "loss": 0.7761,
      "step": 58800
    },
    {
      "epoch": 2.3506475365673576,
      "grad_norm": 3.0591514110565186,
      "learning_rate": 1.0838388676032355e-05,
      "loss": 0.7974,
      "step": 58900
    },
    {
      "epoch": 2.354638516951689,
      "grad_norm": 3.365924835205078,
      "learning_rate": 1.0771871008939975e-05,
      "loss": 0.8262,
      "step": 59000
    },
    {
      "epoch": 2.354638516951689,
      "eval_loss": 0.7880109548568726,
      "eval_runtime": 464.0585,
      "eval_samples_per_second": 13.498,
      "eval_steps_per_second": 13.498,
      "step": 59000
    },
    {
      "epoch": 2.3586294973360205,
      "grad_norm": 2.1991918087005615,
      "learning_rate": 1.0705353341847594e-05,
      "loss": 0.8294,
      "step": 59100
    },
    {
      "epoch": 2.362620477720352,
      "grad_norm": 3.0874884128570557,
      "learning_rate": 1.0638835674755216e-05,
      "loss": 0.8179,
      "step": 59200
    },
    {
      "epoch": 2.3666114581046833,
      "grad_norm": 5.655887126922607,
      "learning_rate": 1.0572318007662836e-05,
      "loss": 0.8073,
      "step": 59300
    },
    {
      "epoch": 2.3706024384890148,
      "grad_norm": 2.5039947032928467,
      "learning_rate": 1.0505800340570456e-05,
      "loss": 0.801,
      "step": 59400
    },
    {
      "epoch": 2.374593418873346,
      "grad_norm": 2.2502264976501465,
      "learning_rate": 1.0439282673478076e-05,
      "loss": 0.8197,
      "step": 59500
    },
    {
      "epoch": 2.374593418873346,
      "eval_loss": 0.7883526682853699,
      "eval_runtime": 433.3177,
      "eval_samples_per_second": 14.456,
      "eval_steps_per_second": 14.456,
      "step": 59500
    },
    {
      "epoch": 2.3785843992576776,
      "grad_norm": 2.0656542778015137,
      "learning_rate": 1.0372765006385698e-05,
      "loss": 0.807,
      "step": 59600
    },
    {
      "epoch": 2.382575379642009,
      "grad_norm": 2.342392921447754,
      "learning_rate": 1.0306247339293316e-05,
      "loss": 0.7724,
      "step": 59700
    },
    {
      "epoch": 2.3865663600263405,
      "grad_norm": 2.946450710296631,
      "learning_rate": 1.0239729672200938e-05,
      "loss": 0.7781,
      "step": 59800
    },
    {
      "epoch": 2.390557340410672,
      "grad_norm": 1.9450329542160034,
      "learning_rate": 1.0173212005108556e-05,
      "loss": 0.8143,
      "step": 59900
    },
    {
      "epoch": 2.3945483207950033,
      "grad_norm": 2.7633001804351807,
      "learning_rate": 1.0106694338016178e-05,
      "loss": 0.851,
      "step": 60000
    },
    {
      "epoch": 2.3945483207950033,
      "eval_loss": 0.7869957089424133,
      "eval_runtime": 424.6269,
      "eval_samples_per_second": 14.752,
      "eval_steps_per_second": 14.752,
      "step": 60000
    },
    {
      "epoch": 2.398539301179335,
      "grad_norm": 2.507399082183838,
      "learning_rate": 1.0040176670923798e-05,
      "loss": 0.8051,
      "step": 60100
    },
    {
      "epoch": 2.402530281563666,
      "grad_norm": 2.6934878826141357,
      "learning_rate": 9.973659003831418e-06,
      "loss": 0.8089,
      "step": 60200
    },
    {
      "epoch": 2.4065212619479976,
      "grad_norm": 2.388422727584839,
      "learning_rate": 9.907141336739038e-06,
      "loss": 0.8029,
      "step": 60300
    },
    {
      "epoch": 2.410512242332329,
      "grad_norm": 1.4450284242630005,
      "learning_rate": 9.840623669646658e-06,
      "loss": 0.7693,
      "step": 60400
    },
    {
      "epoch": 2.4145032227166605,
      "grad_norm": 2.886204481124878,
      "learning_rate": 9.774106002554279e-06,
      "loss": 0.8316,
      "step": 60500
    },
    {
      "epoch": 2.4145032227166605,
      "eval_loss": 0.7865350246429443,
      "eval_runtime": 396.1522,
      "eval_samples_per_second": 15.812,
      "eval_steps_per_second": 15.812,
      "step": 60500
    },
    {
      "epoch": 2.418494203100992,
      "grad_norm": 2.6060237884521484,
      "learning_rate": 9.707588335461899e-06,
      "loss": 0.7769,
      "step": 60600
    },
    {
      "epoch": 2.422485183485323,
      "grad_norm": 2.076984405517578,
      "learning_rate": 9.641735845040443e-06,
      "loss": 0.805,
      "step": 60700
    },
    {
      "epoch": 2.426476163869655,
      "grad_norm": 3.3548057079315186,
      "learning_rate": 9.575218177948063e-06,
      "loss": 0.8119,
      "step": 60800
    },
    {
      "epoch": 2.430467144253986,
      "grad_norm": 2.5284998416900635,
      "learning_rate": 9.508700510855683e-06,
      "loss": 0.8549,
      "step": 60900
    },
    {
      "epoch": 2.4344581246383172,
      "grad_norm": 2.8545374870300293,
      "learning_rate": 9.442182843763305e-06,
      "loss": 0.8265,
      "step": 61000
    },
    {
      "epoch": 2.4344581246383172,
      "eval_loss": 0.7869142889976501,
      "eval_runtime": 333.2607,
      "eval_samples_per_second": 18.796,
      "eval_steps_per_second": 18.796,
      "step": 61000
    },
    {
      "epoch": 2.4384491050226487,
      "grad_norm": 2.596932888031006,
      "learning_rate": 9.375665176670924e-06,
      "loss": 0.7924,
      "step": 61100
    },
    {
      "epoch": 2.44244008540698,
      "grad_norm": 2.8182032108306885,
      "learning_rate": 9.309147509578545e-06,
      "loss": 0.847,
      "step": 61200
    },
    {
      "epoch": 2.4464310657913115,
      "grad_norm": 2.8047499656677246,
      "learning_rate": 9.242629842486165e-06,
      "loss": 0.8181,
      "step": 61300
    },
    {
      "epoch": 2.450422046175643,
      "grad_norm": 3.322293758392334,
      "learning_rate": 9.176112175393786e-06,
      "loss": 0.8327,
      "step": 61400
    },
    {
      "epoch": 2.4544130265599744,
      "grad_norm": 2.559875965118408,
      "learning_rate": 9.109594508301406e-06,
      "loss": 0.8194,
      "step": 61500
    },
    {
      "epoch": 2.4544130265599744,
      "eval_loss": 0.7865894436836243,
      "eval_runtime": 323.6886,
      "eval_samples_per_second": 19.352,
      "eval_steps_per_second": 19.352,
      "step": 61500
    },
    {
      "epoch": 2.458404006944306,
      "grad_norm": 2.3759169578552246,
      "learning_rate": 9.043076841209026e-06,
      "loss": 0.7713,
      "step": 61600
    },
    {
      "epoch": 2.4623949873286373,
      "grad_norm": 2.9534199237823486,
      "learning_rate": 8.976559174116646e-06,
      "loss": 0.8362,
      "step": 61700
    },
    {
      "epoch": 2.4663859677129687,
      "grad_norm": 2.9355125427246094,
      "learning_rate": 8.910041507024266e-06,
      "loss": 0.8094,
      "step": 61800
    },
    {
      "epoch": 2.4703769480973,
      "grad_norm": 2.351595401763916,
      "learning_rate": 8.843523839931886e-06,
      "loss": 0.7467,
      "step": 61900
    },
    {
      "epoch": 2.4743679284816316,
      "grad_norm": 2.2384531497955322,
      "learning_rate": 8.777006172839506e-06,
      "loss": 0.7781,
      "step": 62000
    },
    {
      "epoch": 2.4743679284816316,
      "eval_loss": 0.7852583527565002,
      "eval_runtime": 321.4811,
      "eval_samples_per_second": 19.485,
      "eval_steps_per_second": 19.485,
      "step": 62000
    },
    {
      "epoch": 2.478358908865963,
      "grad_norm": 2.557462692260742,
      "learning_rate": 8.710488505747128e-06,
      "loss": 0.8015,
      "step": 62100
    },
    {
      "epoch": 2.4823498892502944,
      "grad_norm": 1.8242398500442505,
      "learning_rate": 8.643970838654746e-06,
      "loss": 0.7976,
      "step": 62200
    },
    {
      "epoch": 2.486340869634626,
      "grad_norm": 2.551453113555908,
      "learning_rate": 8.577453171562368e-06,
      "loss": 0.7892,
      "step": 62300
    },
    {
      "epoch": 2.4903318500189573,
      "grad_norm": 2.771439790725708,
      "learning_rate": 8.510935504469987e-06,
      "loss": 0.7851,
      "step": 62400
    },
    {
      "epoch": 2.4943228304032887,
      "grad_norm": 2.549513578414917,
      "learning_rate": 8.444417837377608e-06,
      "loss": 0.7658,
      "step": 62500
    },
    {
      "epoch": 2.4943228304032887,
      "eval_loss": 0.7854667901992798,
      "eval_runtime": 317.3529,
      "eval_samples_per_second": 19.738,
      "eval_steps_per_second": 19.738,
      "step": 62500
    },
    {
      "epoch": 2.49831381078762,
      "grad_norm": 2.296243190765381,
      "learning_rate": 8.377900170285228e-06,
      "loss": 0.7927,
      "step": 62600
    },
    {
      "epoch": 2.5023047911719516,
      "grad_norm": 3.500307321548462,
      "learning_rate": 8.311382503192849e-06,
      "loss": 0.7924,
      "step": 62700
    },
    {
      "epoch": 2.5062957715562826,
      "grad_norm": 2.9746837615966797,
      "learning_rate": 8.245530012771393e-06,
      "loss": 0.8215,
      "step": 62800
    },
    {
      "epoch": 2.5102867519406145,
      "grad_norm": 3.065152406692505,
      "learning_rate": 8.179012345679013e-06,
      "loss": 0.7879,
      "step": 62900
    },
    {
      "epoch": 2.5142777323249454,
      "grad_norm": 4.387501239776611,
      "learning_rate": 8.112494678586632e-06,
      "loss": 0.7866,
      "step": 63000
    },
    {
      "epoch": 2.5142777323249454,
      "eval_loss": 0.7857243418693542,
      "eval_runtime": 320.39,
      "eval_samples_per_second": 19.551,
      "eval_steps_per_second": 19.551,
      "step": 63000
    },
    {
      "epoch": 2.518268712709277,
      "grad_norm": 2.3045308589935303,
      "learning_rate": 8.045977011494253e-06,
      "loss": 0.806,
      "step": 63100
    },
    {
      "epoch": 2.5222596930936083,
      "grad_norm": 2.041419506072998,
      "learning_rate": 7.979459344401873e-06,
      "loss": 0.7565,
      "step": 63200
    },
    {
      "epoch": 2.5262506734779397,
      "grad_norm": 2.4658524990081787,
      "learning_rate": 7.912941677309494e-06,
      "loss": 0.7957,
      "step": 63300
    },
    {
      "epoch": 2.530241653862271,
      "grad_norm": 2.129631996154785,
      "learning_rate": 7.846424010217114e-06,
      "loss": 0.829,
      "step": 63400
    },
    {
      "epoch": 2.5342326342466026,
      "grad_norm": 1.469430685043335,
      "learning_rate": 7.779906343124735e-06,
      "loss": 0.8093,
      "step": 63500
    },
    {
      "epoch": 2.5342326342466026,
      "eval_loss": 0.7839583158493042,
      "eval_runtime": 320.0072,
      "eval_samples_per_second": 19.575,
      "eval_steps_per_second": 19.575,
      "step": 63500
    },
    {
      "epoch": 2.538223614630934,
      "grad_norm": 3.130073070526123,
      "learning_rate": 7.713388676032354e-06,
      "loss": 0.8141,
      "step": 63600
    },
    {
      "epoch": 2.5422145950152655,
      "grad_norm": 2.953486919403076,
      "learning_rate": 7.646871008939976e-06,
      "loss": 0.7644,
      "step": 63700
    },
    {
      "epoch": 2.546205575399597,
      "grad_norm": 2.3520123958587646,
      "learning_rate": 7.580353341847594e-06,
      "loss": 0.7692,
      "step": 63800
    },
    {
      "epoch": 2.5501965557839283,
      "grad_norm": 1.7253574132919312,
      "learning_rate": 7.513835674755215e-06,
      "loss": 0.8168,
      "step": 63900
    },
    {
      "epoch": 2.5541875361682598,
      "grad_norm": 2.925302267074585,
      "learning_rate": 7.447318007662836e-06,
      "loss": 0.8414,
      "step": 64000
    },
    {
      "epoch": 2.5541875361682598,
      "eval_loss": 0.784786581993103,
      "eval_runtime": 318.4744,
      "eval_samples_per_second": 19.669,
      "eval_steps_per_second": 19.669,
      "step": 64000
    },
    {
      "epoch": 2.558178516552591,
      "grad_norm": 2.208250045776367,
      "learning_rate": 7.380800340570455e-06,
      "loss": 0.8399,
      "step": 64100
    },
    {
      "epoch": 2.5621694969369226,
      "grad_norm": 2.299666166305542,
      "learning_rate": 7.314282673478076e-06,
      "loss": 0.7664,
      "step": 64200
    },
    {
      "epoch": 2.566160477321254,
      "grad_norm": 2.2817487716674805,
      "learning_rate": 7.247765006385697e-06,
      "loss": 0.8302,
      "step": 64300
    },
    {
      "epoch": 2.5701514577055855,
      "grad_norm": 2.811950922012329,
      "learning_rate": 7.181247339293316e-06,
      "loss": 0.7511,
      "step": 64400
    },
    {
      "epoch": 2.574142438089917,
      "grad_norm": 1.9100689888000488,
      "learning_rate": 7.114729672200937e-06,
      "loss": 0.8159,
      "step": 64500
    },
    {
      "epoch": 2.574142438089917,
      "eval_loss": 0.7835314273834229,
      "eval_runtime": 321.4359,
      "eval_samples_per_second": 19.488,
      "eval_steps_per_second": 19.488,
      "step": 64500
    },
    {
      "epoch": 2.5781334184742484,
      "grad_norm": 2.5574119091033936,
      "learning_rate": 7.0482120051085565e-06,
      "loss": 0.8461,
      "step": 64600
    },
    {
      "epoch": 2.5821243988585794,
      "grad_norm": 2.533926010131836,
      "learning_rate": 6.9816943380161775e-06,
      "loss": 0.7812,
      "step": 64700
    },
    {
      "epoch": 2.5861153792429112,
      "grad_norm": 2.321934938430786,
      "learning_rate": 6.9151766709237984e-06,
      "loss": 0.7822,
      "step": 64800
    },
    {
      "epoch": 2.5901063596272422,
      "grad_norm": 2.1171209812164307,
      "learning_rate": 6.849324180502342e-06,
      "loss": 0.7585,
      "step": 64900
    },
    {
      "epoch": 2.594097340011574,
      "grad_norm": 2.296149969100952,
      "learning_rate": 6.782806513409961e-06,
      "loss": 0.7946,
      "step": 65000
    },
    {
      "epoch": 2.594097340011574,
      "eval_loss": 0.7836622595787048,
      "eval_runtime": 394.2574,
      "eval_samples_per_second": 15.888,
      "eval_steps_per_second": 15.888,
      "step": 65000
    },
    {
      "epoch": 2.598088320395905,
      "grad_norm": 1.9383057355880737,
      "learning_rate": 6.716288846317582e-06,
      "loss": 0.7807,
      "step": 65100
    },
    {
      "epoch": 2.6020793007802365,
      "grad_norm": 1.7739596366882324,
      "learning_rate": 6.649771179225203e-06,
      "loss": 0.7494,
      "step": 65200
    },
    {
      "epoch": 2.606070281164568,
      "grad_norm": 2.8413970470428467,
      "learning_rate": 6.5832535121328225e-06,
      "loss": 0.8199,
      "step": 65300
    },
    {
      "epoch": 2.6100612615488994,
      "grad_norm": 2.4474947452545166,
      "learning_rate": 6.516735845040443e-06,
      "loss": 0.8371,
      "step": 65400
    },
    {
      "epoch": 2.614052241933231,
      "grad_norm": 2.161966562271118,
      "learning_rate": 6.450218177948063e-06,
      "loss": 0.8145,
      "step": 65500
    },
    {
      "epoch": 2.614052241933231,
      "eval_loss": 0.7847723364830017,
      "eval_runtime": 424.9552,
      "eval_samples_per_second": 14.74,
      "eval_steps_per_second": 14.74,
      "step": 65500
    },
    {
      "epoch": 2.6180432223175623,
      "grad_norm": 2.732933282852173,
      "learning_rate": 6.383700510855684e-06,
      "loss": 0.8482,
      "step": 65600
    },
    {
      "epoch": 2.6220342027018937,
      "grad_norm": 2.4841723442077637,
      "learning_rate": 6.3171828437633046e-06,
      "loss": 0.8545,
      "step": 65700
    },
    {
      "epoch": 2.626025183086225,
      "grad_norm": 1.7756669521331787,
      "learning_rate": 6.250665176670924e-06,
      "loss": 0.7869,
      "step": 65800
    },
    {
      "epoch": 2.6300161634705566,
      "grad_norm": 1.9476901292800903,
      "learning_rate": 6.184147509578545e-06,
      "loss": 0.7898,
      "step": 65900
    },
    {
      "epoch": 2.634007143854888,
      "grad_norm": 3.0643296241760254,
      "learning_rate": 6.117629842486165e-06,
      "loss": 0.7956,
      "step": 66000
    },
    {
      "epoch": 2.634007143854888,
      "eval_loss": 0.7825226783752441,
      "eval_runtime": 425.8806,
      "eval_samples_per_second": 14.708,
      "eval_steps_per_second": 14.708,
      "step": 66000
    },
    {
      "epoch": 2.6379981242392194,
      "grad_norm": 2.8043012619018555,
      "learning_rate": 6.051112175393785e-06,
      "loss": 0.8425,
      "step": 66100
    },
    {
      "epoch": 2.641989104623551,
      "grad_norm": 1.9624505043029785,
      "learning_rate": 5.984594508301405e-06,
      "loss": 0.7939,
      "step": 66200
    },
    {
      "epoch": 2.6459800850078823,
      "grad_norm": 1.5658745765686035,
      "learning_rate": 5.918076841209025e-06,
      "loss": 0.8189,
      "step": 66300
    },
    {
      "epoch": 2.6499710653922137,
      "grad_norm": 2.720897912979126,
      "learning_rate": 5.851559174116645e-06,
      "loss": 0.7755,
      "step": 66400
    },
    {
      "epoch": 2.653962045776545,
      "grad_norm": 2.9230172634124756,
      "learning_rate": 5.785041507024265e-06,
      "loss": 0.823,
      "step": 66500
    },
    {
      "epoch": 2.653962045776545,
      "eval_loss": 0.7828843593597412,
      "eval_runtime": 429.1213,
      "eval_samples_per_second": 14.597,
      "eval_steps_per_second": 14.597,
      "step": 66500
    },
    {
      "epoch": 2.657953026160876,
      "grad_norm": 2.294093132019043,
      "learning_rate": 5.718523839931886e-06,
      "loss": 0.77,
      "step": 66600
    },
    {
      "epoch": 2.661944006545208,
      "grad_norm": 2.0660109519958496,
      "learning_rate": 5.652006172839506e-06,
      "loss": 0.8097,
      "step": 66700
    },
    {
      "epoch": 2.665934986929539,
      "grad_norm": 2.3872203826904297,
      "learning_rate": 5.5854885057471265e-06,
      "loss": 0.821,
      "step": 66800
    },
    {
      "epoch": 2.669925967313871,
      "grad_norm": 2.1140735149383545,
      "learning_rate": 5.519636015325671e-06,
      "loss": 0.8166,
      "step": 66900
    },
    {
      "epoch": 2.673916947698202,
      "grad_norm": 2.0524048805236816,
      "learning_rate": 5.453118348233291e-06,
      "loss": 0.7739,
      "step": 67000
    },
    {
      "epoch": 2.673916947698202,
      "eval_loss": 0.7813650369644165,
      "eval_runtime": 432.8914,
      "eval_samples_per_second": 14.47,
      "eval_steps_per_second": 14.47,
      "step": 67000
    },
    {
      "epoch": 2.6779079280825338,
      "grad_norm": 1.9005756378173828,
      "learning_rate": 5.386600681140911e-06,
      "loss": 0.7962,
      "step": 67100
    },
    {
      "epoch": 2.6818989084668647,
      "grad_norm": 2.311872959136963,
      "learning_rate": 5.320083014048532e-06,
      "loss": 0.7727,
      "step": 67200
    },
    {
      "epoch": 2.685889888851196,
      "grad_norm": 2.0703036785125732,
      "learning_rate": 5.253565346956152e-06,
      "loss": 0.8117,
      "step": 67300
    },
    {
      "epoch": 2.6898808692355276,
      "grad_norm": 1.1897560358047485,
      "learning_rate": 5.187047679863772e-06,
      "loss": 0.761,
      "step": 67400
    },
    {
      "epoch": 2.693871849619859,
      "grad_norm": 2.589510202407837,
      "learning_rate": 5.1205300127713924e-06,
      "loss": 0.8014,
      "step": 67500
    },
    {
      "epoch": 2.693871849619859,
      "eval_loss": 0.7813759446144104,
      "eval_runtime": 427.0325,
      "eval_samples_per_second": 14.669,
      "eval_steps_per_second": 14.669,
      "step": 67500
    },
    {
      "epoch": 2.6978628300041905,
      "grad_norm": 2.4836766719818115,
      "learning_rate": 5.0540123456790125e-06,
      "loss": 0.7852,
      "step": 67600
    },
    {
      "epoch": 2.701853810388522,
      "grad_norm": 2.0025928020477295,
      "learning_rate": 4.987494678586633e-06,
      "loss": 0.7651,
      "step": 67700
    },
    {
      "epoch": 2.7058447907728533,
      "grad_norm": 2.6136584281921387,
      "learning_rate": 4.920977011494253e-06,
      "loss": 0.7989,
      "step": 67800
    },
    {
      "epoch": 2.7098357711571848,
      "grad_norm": 2.2389137744903564,
      "learning_rate": 4.854459344401873e-06,
      "loss": 0.7946,
      "step": 67900
    },
    {
      "epoch": 2.713826751541516,
      "grad_norm": 2.8402059078216553,
      "learning_rate": 4.787941677309494e-06,
      "loss": 0.8128,
      "step": 68000
    },
    {
      "epoch": 2.713826751541516,
      "eval_loss": 0.781188428401947,
      "eval_runtime": 430.045,
      "eval_samples_per_second": 14.566,
      "eval_steps_per_second": 14.566,
      "step": 68000
    },
    {
      "epoch": 2.7178177319258476,
      "grad_norm": 2.442035675048828,
      "learning_rate": 4.721424010217114e-06,
      "loss": 0.7913,
      "step": 68100
    },
    {
      "epoch": 2.721808712310179,
      "grad_norm": 2.8172988891601562,
      "learning_rate": 4.654906343124734e-06,
      "loss": 0.7547,
      "step": 68200
    },
    {
      "epoch": 2.7257996926945105,
      "grad_norm": 2.6309025287628174,
      "learning_rate": 4.588388676032354e-06,
      "loss": 0.7564,
      "step": 68300
    },
    {
      "epoch": 2.729790673078842,
      "grad_norm": 2.539274215698242,
      "learning_rate": 4.521871008939975e-06,
      "loss": 0.7595,
      "step": 68400
    },
    {
      "epoch": 2.7337816534631734,
      "grad_norm": 2.0220327377319336,
      "learning_rate": 4.455353341847595e-06,
      "loss": 0.7994,
      "step": 68500
    },
    {
      "epoch": 2.7337816534631734,
      "eval_loss": 0.7814123630523682,
      "eval_runtime": 439.2165,
      "eval_samples_per_second": 14.262,
      "eval_steps_per_second": 14.262,
      "step": 68500
    },
    {
      "epoch": 2.737772633847505,
      "grad_norm": 2.5894267559051514,
      "learning_rate": 4.388835674755215e-06,
      "loss": 0.8084,
      "step": 68600
    },
    {
      "epoch": 2.741763614231836,
      "grad_norm": 2.2122855186462402,
      "learning_rate": 4.322318007662835e-06,
      "loss": 0.7962,
      "step": 68700
    },
    {
      "epoch": 2.7457545946161677,
      "grad_norm": 2.63509202003479,
      "learning_rate": 4.255800340570456e-06,
      "loss": 0.7817,
      "step": 68800
    },
    {
      "epoch": 2.7497455750004987,
      "grad_norm": 2.684103488922119,
      "learning_rate": 4.189947850148999e-06,
      "loss": 0.7954,
      "step": 68900
    },
    {
      "epoch": 2.7537365553848305,
      "grad_norm": 2.6196658611297607,
      "learning_rate": 4.12343018305662e-06,
      "loss": 0.8246,
      "step": 69000
    },
    {
      "epoch": 2.7537365553848305,
      "eval_loss": 0.7807196378707886,
      "eval_runtime": 445.9752,
      "eval_samples_per_second": 14.046,
      "eval_steps_per_second": 14.046,
      "step": 69000
    },
    {
      "epoch": 2.7577275357691615,
      "grad_norm": 2.682342290878296,
      "learning_rate": 4.05691251596424e-06,
      "loss": 0.808,
      "step": 69100
    },
    {
      "epoch": 2.761718516153493,
      "grad_norm": 3.063276767730713,
      "learning_rate": 3.99039484887186e-06,
      "loss": 0.789,
      "step": 69200
    },
    {
      "epoch": 2.7657094965378244,
      "grad_norm": 2.664398431777954,
      "learning_rate": 3.923877181779481e-06,
      "loss": 0.7851,
      "step": 69300
    },
    {
      "epoch": 2.769700476922156,
      "grad_norm": 1.918479084968567,
      "learning_rate": 3.857359514687101e-06,
      "loss": 0.7851,
      "step": 69400
    },
    {
      "epoch": 2.7736914573064873,
      "grad_norm": 3.8535664081573486,
      "learning_rate": 3.7908418475947214e-06,
      "loss": 0.7807,
      "step": 69500
    },
    {
      "epoch": 2.7736914573064873,
      "eval_loss": 0.7818132042884827,
      "eval_runtime": 451.9658,
      "eval_samples_per_second": 13.859,
      "eval_steps_per_second": 13.859,
      "step": 69500
    },
    {
      "epoch": 2.7776824376908187,
      "grad_norm": 2.0736687183380127,
      "learning_rate": 3.7243241805023415e-06,
      "loss": 0.7896,
      "step": 69600
    },
    {
      "epoch": 2.78167341807515,
      "grad_norm": 2.61366868019104,
      "learning_rate": 3.657806513409962e-06,
      "loss": 0.791,
      "step": 69700
    },
    {
      "epoch": 2.7856643984594815,
      "grad_norm": 2.611069917678833,
      "learning_rate": 3.591288846317582e-06,
      "loss": 0.7932,
      "step": 69800
    },
    {
      "epoch": 2.789655378843813,
      "grad_norm": 2.5013153553009033,
      "learning_rate": 3.524771179225202e-06,
      "loss": 0.7772,
      "step": 69900
    },
    {
      "epoch": 2.7936463592281444,
      "grad_norm": 1.8462101221084595,
      "learning_rate": 3.4582535121328223e-06,
      "loss": 0.8275,
      "step": 70000
    },
    {
      "epoch": 2.7936463592281444,
      "eval_loss": 0.780068576335907,
      "eval_runtime": 435.4848,
      "eval_samples_per_second": 14.384,
      "eval_steps_per_second": 14.384,
      "step": 70000
    },
    {
      "epoch": 2.797637339612476,
      "grad_norm": 2.425407886505127,
      "learning_rate": 3.3917358450404433e-06,
      "loss": 0.8082,
      "step": 70100
    },
    {
      "epoch": 2.8016283199968073,
      "grad_norm": 2.0904886722564697,
      "learning_rate": 3.3252181779480634e-06,
      "loss": 0.7763,
      "step": 70200
    },
    {
      "epoch": 2.8056193003811387,
      "grad_norm": 3.039844036102295,
      "learning_rate": 3.2587005108556835e-06,
      "loss": 0.8196,
      "step": 70300
    },
    {
      "epoch": 2.80961028076547,
      "grad_norm": 2.0432984828948975,
      "learning_rate": 3.1921828437633036e-06,
      "loss": 0.7861,
      "step": 70400
    },
    {
      "epoch": 2.8136012611498016,
      "grad_norm": 3.3827364444732666,
      "learning_rate": 3.125665176670924e-06,
      "loss": 0.8067,
      "step": 70500
    },
    {
      "epoch": 2.8136012611498016,
      "eval_loss": 0.7801620960235596,
      "eval_runtime": 428.9983,
      "eval_samples_per_second": 14.601,
      "eval_steps_per_second": 14.601,
      "step": 70500
    },
    {
      "epoch": 2.817592241534133,
      "grad_norm": 3.330456495285034,
      "learning_rate": 3.059147509578544e-06,
      "loss": 0.81,
      "step": 70600
    },
    {
      "epoch": 2.8215832219184644,
      "grad_norm": 2.015442371368408,
      "learning_rate": 2.9926298424861643e-06,
      "loss": 0.7927,
      "step": 70700
    },
    {
      "epoch": 2.8255742023027954,
      "grad_norm": 2.2341978549957275,
      "learning_rate": 2.926112175393785e-06,
      "loss": 0.801,
      "step": 70800
    },
    {
      "epoch": 2.8295651826871273,
      "grad_norm": 2.8972232341766357,
      "learning_rate": 2.859594508301405e-06,
      "loss": 0.7855,
      "step": 70900
    },
    {
      "epoch": 2.8335561630714583,
      "grad_norm": 2.9777519702911377,
      "learning_rate": 2.793742017879949e-06,
      "loss": 0.7982,
      "step": 71000
    },
    {
      "epoch": 2.8335561630714583,
      "eval_loss": 0.7794036865234375,
      "eval_runtime": 428.6148,
      "eval_samples_per_second": 14.615,
      "eval_steps_per_second": 14.615,
      "step": 71000
    },
    {
      "epoch": 2.83754714345579,
      "grad_norm": 3.1536967754364014,
      "learning_rate": 2.727224350787569e-06,
      "loss": 0.8109,
      "step": 71100
    },
    {
      "epoch": 2.841538123840121,
      "grad_norm": 2.1607298851013184,
      "learning_rate": 2.6607066836951896e-06,
      "loss": 0.7651,
      "step": 71200
    },
    {
      "epoch": 2.8455291042244526,
      "grad_norm": 1.938719391822815,
      "learning_rate": 2.5941890166028097e-06,
      "loss": 0.8065,
      "step": 71300
    },
    {
      "epoch": 2.849520084608784,
      "grad_norm": 2.7298383712768555,
      "learning_rate": 2.52767134951043e-06,
      "loss": 0.8263,
      "step": 71400
    },
    {
      "epoch": 2.8535110649931155,
      "grad_norm": 1.0608422756195068,
      "learning_rate": 2.4611536824180503e-06,
      "loss": 0.8056,
      "step": 71500
    },
    {
      "epoch": 2.8535110649931155,
      "eval_loss": 0.7802795767784119,
      "eval_runtime": 431.1591,
      "eval_samples_per_second": 14.528,
      "eval_steps_per_second": 14.528,
      "step": 71500
    },
    {
      "epoch": 2.857502045377447,
      "grad_norm": 2.829148292541504,
      "learning_rate": 2.394636015325671e-06,
      "loss": 0.8171,
      "step": 71600
    },
    {
      "epoch": 2.8614930257617783,
      "grad_norm": 1.7642632722854614,
      "learning_rate": 2.328118348233291e-06,
      "loss": 0.7372,
      "step": 71700
    },
    {
      "epoch": 2.8654840061461098,
      "grad_norm": 2.7227566242218018,
      "learning_rate": 2.261600681140911e-06,
      "loss": 0.7573,
      "step": 71800
    },
    {
      "epoch": 2.869474986530441,
      "grad_norm": 3.2289271354675293,
      "learning_rate": 2.195083014048531e-06,
      "loss": 0.7868,
      "step": 71900
    },
    {
      "epoch": 2.8734659669147726,
      "grad_norm": 2.0945467948913574,
      "learning_rate": 2.1285653469561517e-06,
      "loss": 0.8341,
      "step": 72000
    },
    {
      "epoch": 2.8734659669147726,
      "eval_loss": 0.7802762985229492,
      "eval_runtime": 436.3863,
      "eval_samples_per_second": 14.354,
      "eval_steps_per_second": 14.354,
      "step": 72000
    },
    {
      "epoch": 2.877456947299104,
      "grad_norm": 2.4346799850463867,
      "learning_rate": 2.0620476798637718e-06,
      "loss": 0.7799,
      "step": 72100
    },
    {
      "epoch": 2.8814479276834355,
      "grad_norm": 2.74485445022583,
      "learning_rate": 1.9955300127713923e-06,
      "loss": 0.7957,
      "step": 72200
    },
    {
      "epoch": 2.885438908067767,
      "grad_norm": 2.868328332901001,
      "learning_rate": 1.9290123456790124e-06,
      "loss": 0.7752,
      "step": 72300
    },
    {
      "epoch": 2.8894298884520984,
      "grad_norm": 2.756166934967041,
      "learning_rate": 1.8624946785866327e-06,
      "loss": 0.7994,
      "step": 72400
    },
    {
      "epoch": 2.89342086883643,
      "grad_norm": 2.98354172706604,
      "learning_rate": 1.7959770114942528e-06,
      "loss": 0.8506,
      "step": 72500
    },
    {
      "epoch": 2.89342086883643,
      "eval_loss": 0.7798334956169128,
      "eval_runtime": 446.5532,
      "eval_samples_per_second": 14.027,
      "eval_steps_per_second": 14.027,
      "step": 72500
    },
    {
      "epoch": 2.8974118492207612,
      "grad_norm": 2.1328177452087402,
      "learning_rate": 1.7294593444018733e-06,
      "loss": 0.8172,
      "step": 72600
    },
    {
      "epoch": 2.901402829605092,
      "grad_norm": 4.74981164932251,
      "learning_rate": 1.6629416773094934e-06,
      "loss": 0.7609,
      "step": 72700
    },
    {
      "epoch": 2.905393809989424,
      "grad_norm": 2.0550875663757324,
      "learning_rate": 1.5964240102171137e-06,
      "loss": 0.7782,
      "step": 72800
    },
    {
      "epoch": 2.909384790373755,
      "grad_norm": 3.3020520210266113,
      "learning_rate": 1.529906343124734e-06,
      "loss": 0.7804,
      "step": 72900
    },
    {
      "epoch": 2.913375770758087,
      "grad_norm": 2.7261710166931152,
      "learning_rate": 1.464053852703278e-06,
      "loss": 0.7706,
      "step": 73000
    },
    {
      "epoch": 2.913375770758087,
      "eval_loss": 0.779228150844574,
      "eval_runtime": 444.8234,
      "eval_samples_per_second": 14.082,
      "eval_steps_per_second": 14.082,
      "step": 73000
    },
    {
      "epoch": 2.917366751142418,
      "grad_norm": 2.722639322280884,
      "learning_rate": 1.3975361856108984e-06,
      "loss": 0.799,
      "step": 73100
    },
    {
      "epoch": 2.92135773152675,
      "grad_norm": 2.6341447830200195,
      "learning_rate": 1.3310185185185185e-06,
      "loss": 0.7646,
      "step": 73200
    },
    {
      "epoch": 2.925348711911081,
      "grad_norm": 2.0721404552459717,
      "learning_rate": 1.2645008514261388e-06,
      "loss": 0.7717,
      "step": 73300
    },
    {
      "epoch": 2.9293396922954122,
      "grad_norm": 2.5484702587127686,
      "learning_rate": 1.1979831843337591e-06,
      "loss": 0.8155,
      "step": 73400
    },
    {
      "epoch": 2.9333306726797437,
      "grad_norm": 1.8932921886444092,
      "learning_rate": 1.1314655172413795e-06,
      "loss": 0.7976,
      "step": 73500
    },
    {
      "epoch": 2.9333306726797437,
      "eval_loss": 0.7785211205482483,
      "eval_runtime": 431.2321,
      "eval_samples_per_second": 14.526,
      "eval_steps_per_second": 14.526,
      "step": 73500
    },
    {
      "epoch": 2.937321653064075,
      "grad_norm": 2.1106607913970947,
      "learning_rate": 1.0649478501489996e-06,
      "loss": 0.8073,
      "step": 73600
    },
    {
      "epoch": 2.9413126334484065,
      "grad_norm": 2.554126739501953,
      "learning_rate": 9.984301830566199e-07,
      "loss": 0.8142,
      "step": 73700
    },
    {
      "epoch": 2.945303613832738,
      "grad_norm": 2.4365344047546387,
      "learning_rate": 9.319125159642402e-07,
      "loss": 0.8076,
      "step": 73800
    },
    {
      "epoch": 2.9492945942170694,
      "grad_norm": 3.140251398086548,
      "learning_rate": 8.653948488718604e-07,
      "loss": 0.7875,
      "step": 73900
    },
    {
      "epoch": 2.953285574601401,
      "grad_norm": 2.4455935955047607,
      "learning_rate": 7.988771817794807e-07,
      "loss": 0.805,
      "step": 74000
    },
    {
      "epoch": 2.953285574601401,
      "eval_loss": 0.7791297435760498,
      "eval_runtime": 431.587,
      "eval_samples_per_second": 14.514,
      "eval_steps_per_second": 14.514,
      "step": 74000
    },
    {
      "epoch": 2.9572765549857323,
      "grad_norm": 1.8737305402755737,
      "learning_rate": 7.323595146871009e-07,
      "loss": 0.7639,
      "step": 74100
    },
    {
      "epoch": 2.9612675353700637,
      "grad_norm": 2.773693561553955,
      "learning_rate": 6.658418475947212e-07,
      "loss": 0.8233,
      "step": 74200
    },
    {
      "epoch": 2.965258515754395,
      "grad_norm": 2.392893075942993,
      "learning_rate": 5.993241805023414e-07,
      "loss": 0.7924,
      "step": 74300
    },
    {
      "epoch": 2.9692494961387266,
      "grad_norm": 2.029088258743286,
      "learning_rate": 5.328065134099617e-07,
      "loss": 0.8253,
      "step": 74400
    },
    {
      "epoch": 2.973240476523058,
      "grad_norm": 2.4957351684570312,
      "learning_rate": 4.6628884631758195e-07,
      "loss": 0.8062,
      "step": 74500
    },
    {
      "epoch": 2.973240476523058,
      "eval_loss": 0.7789673805236816,
      "eval_runtime": 431.6372,
      "eval_samples_per_second": 14.512,
      "eval_steps_per_second": 14.512,
      "step": 74500
    },
    {
      "epoch": 2.9772314569073894,
      "grad_norm": 2.6570136547088623,
      "learning_rate": 3.997711792252022e-07,
      "loss": 0.8349,
      "step": 74600
    },
    {
      "epoch": 2.981222437291721,
      "grad_norm": 2.42143177986145,
      "learning_rate": 3.3325351213282247e-07,
      "loss": 0.7983,
      "step": 74700
    },
    {
      "epoch": 2.985213417676052,
      "grad_norm": 2.9600179195404053,
      "learning_rate": 2.667358450404428e-07,
      "loss": 0.7868,
      "step": 74800
    },
    {
      "epoch": 2.9892043980603837,
      "grad_norm": 0.7329452633857727,
      "learning_rate": 2.0021817794806302e-07,
      "loss": 0.7903,
      "step": 74900
    },
    {
      "epoch": 2.9931953784447147,
      "grad_norm": 2.5128440856933594,
      "learning_rate": 1.3370051085568328e-07,
      "loss": 0.7721,
      "step": 75000
    },
    {
      "epoch": 2.9931953784447147,
      "eval_loss": 0.7786982655525208,
      "eval_runtime": 434.6872,
      "eval_samples_per_second": 14.41,
      "eval_steps_per_second": 14.41,
      "step": 75000
    },
    {
      "epoch": 2.9971863588290466,
      "grad_norm": 2.322737693786621,
      "learning_rate": 6.784802043422733e-08,
      "loss": 0.8495,
      "step": 75100
    }
  ],
  "logging_steps": 100,
  "max_steps": 75168,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9640538169344e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
